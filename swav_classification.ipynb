{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SwAv - Unsupervised Learning of Visual Features by Contrasting Cluster Assignments"
      ],
      "metadata": {
        "id": "piGkejfKcahG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Current Colab's Setup"
      ],
      "metadata": {
        "id": "O3WV5xyBc4bC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "s8WY9feLb-U2",
        "outputId": "a754fc9b-6098-4da2-b850-f05eb49fd6c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.3.1+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeM2pwz-nvJm",
        "outputId": "1ff85975-1f45-4615-ea64-6a217b132a82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhoFi2wdcNdg",
        "outputId": "a6dee59a-461b-49e2-8caf-1141c3f9105d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Aug 12 06:47:25 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEI5LsxHcHRE",
        "outputId": "da127cfb-cfab-455f-8238-863fa9786c43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Initial Setup\n",
        "\n"
      ],
      "metadata": {
        "id": "YwrQuNildFnn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1. Clonning the repository"
      ],
      "metadata": {
        "id": "QpkqzI7AFLSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/facebookresearch/swav.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJaeJ6GIbVxo",
        "outputId": "aa21dabf-f30b-4235-ca5d-091853bd8760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'swav'...\n",
            "remote: Enumerating objects: 163, done.\u001b[K\n",
            "remote: Counting objects: 100% (96/96), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 163 (delta 77), reused 63 (delta 63), pack-reused 67\u001b[K\n",
            "Receiving objects: 100% (163/163), 65.50 KiB | 482.00 KiB/s, done.\n",
            "Resolving deltas: 100% (111/111), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2. Mounting Google Drives Files"
      ],
      "metadata": {
        "id": "et2LhfBcdKZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZJ8dYGtMlk-",
        "outputId": "ddcd03dd-3464-4f2d-c9e9-c8579304bc04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3. Set environments variables"
      ],
      "metadata": {
        "id": "-kjiAlJdFZSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%env EXPERIMENT_PATH=/content/drive/MyDrive/PLAEX/Selfsupervised_models/swav/experiments/swav_400ep_bs256_pretrain\n",
        "%env DATASET_PATH=/content/drive/MyDrive/PLAEX/Dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svBgf3qkNErg",
        "outputId": "507d7596-e90b-4d52-bb86-178d106b8735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: EXPERIMENT_PATH=/content/drive/MyDrive/PLAEX/Selfsupervised_models/swav/experiments/swav_400ep_bs256_pretrain\n",
            "env: DATASET_PATH=/content/drive/MyDrive/PLAEX/Dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4. Check if Dataset and Environment paths exist"
      ],
      "metadata": {
        "id": "T3g4r2YVHYnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "%cd /content\n",
        "\n",
        "# For EXPERIMENT_PATH\n",
        "dir_path = os.getenv('EXPERIMENT_PATH') # '/content/swav/experiments/swav_200ep_bs256_pretrain'\n",
        "if os.path.exists(dir_path):\n",
        "    print(f\"The directory '{dir_path}' exists.\")\n",
        "else:\n",
        "    os.makedirs(dir_path, exist_ok=True)\n",
        "    print(f\"Directory '{dir_path}' created successfully.\")\n",
        "\n",
        "# For DATASET_PATH\n",
        "dataset_path = os.getenv('DATASET_PATH') # '/content/drive/MyDrive/PLAEX/Dataset'\n",
        "# Check if the directory exists\n",
        "if os.path.exists(dataset_path):\n",
        "    print(f\"The directory '{dataset_path}' exists.\")\n",
        "else:\n",
        "    print(f\"The directory '{dataset_path}' does not exist.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOwsKqQSL491",
        "outputId": "3ca7591e-6c0f-4afb-92b7-73cd7224b16d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "The directory '/content/drive/MyDrive/PLAEX/Selfsupervised_models/swav/experiments/swav_400ep_bs256_pretrain' exists.\n",
            "The directory '/content/drive/MyDrive/PLAEX/Dataset' exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.5. Copy our modificated codes to SwAV repository"
      ],
      "metadata": {
        "id": "hXvPnKRXHM50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/PLAEX/Selfsupervised_models/swav/code/main_swav_no_apex.py /content/swav/\n",
        "!cp -f /content/drive/MyDrive/PLAEX/Selfsupervised_models/swav/code/utils.py /content/swav/src/\n",
        "!cp /content/drive/MyDrive/PLAEX/Selfsupervised_models/swav/code/eval_linear_no_distribution.py /content/swav/\n"
      ],
      "metadata": {
        "id": "pkw8VC7IK1qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Training and Evaluating SwAV\n",
        "The training is divided into 2 main steps:\n",
        "\n",
        "\n",
        "*   Self supervised training of SwAV model: In order to cluster the features of the images. But not predicting the classification as paper, plastic, etc.\n",
        "*   Supervised Linear Classification training on top of SwaV: After getting the cluster of the features is necessary to classify them into the label that we want as paper, plastic, etc.\n",
        "\n",
        "This process is common on this type of classification task in selfsupervised models.\n",
        "\n"
      ],
      "metadata": {
        "id": "qwbAzy3TFfSp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1. Self supervised training of SwAV model"
      ],
      "metadata": {
        "id": "MeKeoSZDG0dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/swav\n",
        "!python main_swav_no_apex.py \\\n",
        "--data_path $DATASET_PATH \\\n",
        "--epochs 200 \\\n",
        "--base_lr 0.6 \\\n",
        "--final_lr 0.0006 \\\n",
        "--warmup_epochs 0 \\\n",
        "--batch_size 32 \\\n",
        "--size_crops 224 96 \\\n",
        "--nmb_crops 2 6 \\\n",
        "--min_scale_crops 0.14 0.05 \\\n",
        "--max_scale_crops 1. 0.14 \\\n",
        "--use_fp16 true \\\n",
        "--freeze_prototypes_niters 5005 \\\n",
        "--queue_length 3840 \\\n",
        "--epoch_queue_starts 15 \\\n",
        "--crops_for_assign 0 1 \\\n",
        "--temperature 0.1 \\\n",
        "--epsilon 0.05 \\\n",
        "--sinkhorn_iterations 3 \\\n",
        "--feat_dim 128 \\\n",
        "--nmb_prototypes 3000 \\\n",
        "--wd 0.000001 \\\n",
        "--arch resnet50 \\\n",
        "--dump_path $EXPERIMENT_PATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wnLDoiH-apt",
        "outputId": "1a3fa7e6-1d3d-4280-fd0c-7295f9d50b39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/swav\n",
            "INFO - 08/12/24 07:14:58 - 0:00:00 - ============ Initialized logger ============\n",
            "INFO - 08/12/24 07:14:58 - 0:00:01 - arch: resnet50\n",
            "                                     base_lr: 0.6\n",
            "                                     batch_size: 32\n",
            "                                     checkpoint_freq: 25\n",
            "                                     crops_for_assign: [0, 1]\n",
            "                                     data_path: /content/drive/MyDrive/PLAEX/Dataset\n",
            "                                     dump_checkpoints: /content/drive/MyDrive/PLAEX/Selfsupervised_models/swav/experiments/swav_400ep_bs256_pretrain/checkpoints\n",
            "                                     dump_path: /content/drive/MyDrive/PLAEX/Selfsupervised_models/swav/experiments/swav_400ep_bs256_pretrain\n",
            "                                     epoch_queue_starts: 15\n",
            "                                     epochs: 200\n",
            "                                     epsilon: 0.05\n",
            "                                     feat_dim: 128\n",
            "                                     final_lr: 0.0006\n",
            "                                     freeze_prototypes_niters: 5005\n",
            "                                     hidden_mlp: 2048\n",
            "                                     max_scale_crops: [1.0, 0.14]\n",
            "                                     min_scale_crops: [0.14, 0.05]\n",
            "                                     nmb_crops: [2, 6]\n",
            "                                     nmb_prototypes: 3000\n",
            "                                     queue_length: 3840\n",
            "                                     seed: 31\n",
            "                                     sinkhorn_iterations: 3\n",
            "                                     size_crops: [224, 96]\n",
            "                                     start_warmup: 0\n",
            "                                     temperature: 0.1\n",
            "                                     use_fp16: True\n",
            "                                     warmup_epochs: 0\n",
            "                                     wd: 1e-06\n",
            "                                     workers: 10\n",
            "INFO - 08/12/24 07:14:58 - 0:00:01 - The experiment will be stored in /content/drive/MyDrive/PLAEX/Selfsupervised_models/swav/experiments/swav_400ep_bs256_pretrain\n",
            "                                     \n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "INFO - 08/12/24 07:14:58 - 0:00:01 - Building data done with 34 images loaded.\n",
            "INFO - 08/12/24 07:14:59 - 0:00:01 - ResNet(\n",
            "                                       (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "                                       (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                       (relu): ReLU(inplace=True)\n",
            "                                       (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "                                       (layer1): Sequential(\n",
            "                                         (0): Bottleneck(\n",
            "                                           (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                           (downsample): Sequential(\n",
            "                                             (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           )\n",
            "                                         )\n",
            "                                         (1): Bottleneck(\n",
            "                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                         )\n",
            "                                         (2): Bottleneck(\n",
            "                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                         )\n",
            "                                       )\n",
            "                                       (layer2): Sequential(\n",
            "                                         (0): Bottleneck(\n",
            "                                           (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                           (downsample): Sequential(\n",
            "                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           )\n",
            "                                         )\n",
            "                                         (1): Bottleneck(\n",
            "                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                         )\n",
            "                                         (2): Bottleneck(\n",
            "                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                         )\n",
            "                                         (3): Bottleneck(\n",
            "                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                         )\n",
            "                                       )\n",
            "                                       (layer3): Sequential(\n",
            "                                         (0): Bottleneck(\n",
            "                                           (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                           (downsample): Sequential(\n",
            "                                             (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "                                             (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           )\n",
            "                                         )\n",
            "                                         (1): Bottleneck(\n",
            "                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                         )\n",
            "                                         (2): Bottleneck(\n",
            "                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                         )\n",
            "                                         (3): Bottleneck(\n",
            "                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                         )\n",
            "                                         (4): Bottleneck(\n",
            "                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                         )\n",
            "                                         (5): Bottleneck(\n",
            "                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                         )\n",
            "                                       )\n",
            "                                       (layer4): Sequential(\n",
            "                                         (0): Bottleneck(\n",
            "                                           (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                           (downsample): Sequential(\n",
            "                                             (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "                                             (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           )\n",
            "                                         )\n",
            "                                         (1): Bottleneck(\n",
            "                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                         )\n",
            "                                         (2): Bottleneck(\n",
            "                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                         )\n",
            "                                       )\n",
            "                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "                                       (projection_head): Sequential(\n",
            "                                         (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "                                         (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                         (2): ReLU(inplace=True)\n",
            "                                         (3): Linear(in_features=2048, out_features=128, bias=True)\n",
            "                                       )\n",
            "                                       (prototypes): Linear(in_features=128, out_features=3000, bias=False)\n",
            "                                     )\n",
            "INFO - 08/12/24 07:14:59 - 0:00:01 - Building model done.\n",
            "INFO - 08/12/24 07:14:59 - 0:00:01 - Building optimizer done.\n",
            "INFO - 08/12/24 07:14:59 - 0:00:01 - Initializing mixed precision done.\n",
            "INFO - 08/12/24 07:14:59 - 0:00:01 - Found checkpoint at /content/drive/MyDrive/PLAEX/Selfsupervised_models/swav/experiments/swav_400ep_bs256_pretrain/swav_400ep_bs256_pretrain.pth.tar\n",
            "WARNING - 08/12/24 07:14:59 - 0:00:01 - => failed to load state_dict from checkpoint '/content/drive/MyDrive/PLAEX/Selfsupervised_models/swav/experiments/swav_400ep_bs256_pretrain/swav_400ep_bs256_pretrain.pth.tar'\n",
            "WARNING - 08/12/24 07:14:59 - 0:00:01 - => failed to load optimizer from checkpoint '/content/drive/MyDrive/PLAEX/Selfsupervised_models/swav/experiments/swav_400ep_bs256_pretrain/swav_400ep_bs256_pretrain.pth.tar'\n",
            "INFO - 08/12/24 07:15:00 - 0:00:02 - ============ Starting epoch 0 ... ============\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/swav/main_swav_no_apex.py\", line 320, in <module>\n",
            "    main()\n",
            "  File \"/content/swav/main_swav_no_apex.py\", line 180, in main\n",
            "    scores, queue = train(train_loader, model, optimizer, epoch, queue, lr_schedule, scaler)\n",
            "  File \"/content/swav/main_swav_no_apex.py\", line 263, in train\n",
            "    scaler.scale(loss).backward()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 525, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 267, in backward\n",
            "    _engine_run_backward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\", line 744, in _engine_run_backward\n",
            "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy final modifications into our Google Drive files"
      ],
      "metadata": {
        "id": "E9KyHG3_IeMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -f /content/swav/main_swav_no_apex.py /content/drive/MyDrive/PLAEX/Selfsupervised_models/swav/code/\n",
        "!cp -f /content/swav/src/utils.py /content/drive/MyDrive/PLAEX/Selfsupervised_models/swav/code/"
      ],
      "metadata": {
        "id": "bcmX2jUCdVJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2. Supervised learning of Linear Classification on top of SwAV model"
      ],
      "metadata": {
        "id": "Z8wVkXzEG_Cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "checkpoint = \"swav_400ep_bs256_pretrain.pth.tar\"\n",
        "os.environ['CHECKPOINT'] = checkpoint\n",
        "\n",
        "%cd /content/swav\n",
        "!python eval_linear_no_distribution.py \\\n",
        "--data_path $DATASET_PATH \\\n",
        "--pretrained $EXPERIMENT_PATH/$CHECKPOINT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGJx9u7OHEV0",
        "outputId": "862bf95f-fb1b-4026-fd3b-768417f8c765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/swav\n",
            "INFO - 08/12/24 07:24:05 - 0:00:00 - ============ Initialized logger ============\n",
            "INFO - 08/12/24 07:24:05 - 0:00:00 - arch: resnet50\n",
            "                                     batch_size: 32\n",
            "                                     data_path: /content/drive/MyDrive/PLAEX/Dataset\n",
            "                                     decay_epochs: [60, 80]\n",
            "                                     dump_checkpoints: ./checkpoints\n",
            "                                     dump_path: .\n",
            "                                     epochs: 100\n",
            "                                     final_lr: 0\n",
            "                                     gamma: 0.1\n",
            "                                     global_pooling: True\n",
            "                                     lr: 0.3\n",
            "                                     nesterov: False\n",
            "                                     pretrained: /content/drive/MyDrive/PLAEX/Selfsupervised_models/swav/experiments/swav_400ep_bs256_pretrain/swav_400ep_bs256_pretrain.pth.tar\n",
            "                                     scheduler_type: cosine\n",
            "                                     seed: 31\n",
            "                                     use_bn: False\n",
            "                                     wd: 1e-06\n",
            "                                     workers: 10\n",
            "INFO - 08/12/24 07:24:05 - 0:00:00 - The experiment will be stored in .\n",
            "                                     \n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "INFO - 08/12/24 07:24:05 - 0:00:00 - Building data done\n",
            "INFO - 08/12/24 07:24:06 - 0:00:01 - Load pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['projection_head.0.weight', 'projection_head.0.bias', 'projection_head.1.weight', 'projection_head.1.bias', 'projection_head.1.running_mean', 'projection_head.1.running_var', 'projection_head.1.num_batches_tracked', 'projection_head.3.weight', 'projection_head.3.bias', 'prototypes.weight'])\n",
            "INFO - 08/12/24 07:24:06 - 0:00:01 - No checkpoint has found at ./checkpoint.pth.tar\n",
            "INFO - 08/12/24 07:24:06 - 0:00:01 - ============ Starting epoch 0 ... ============\n",
            "INFO - 08/12/24 07:24:08 - 0:00:03 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:08 - 0:00:03 - Epoch[0] - Iter: [0/2]\tTime 2.130 (2.130)\tData 0.632 (0.632)\tLoss 6.9687 (6.9687)\tPrec 0.000 (0.000)\tLR 0.3\n",
            "INFO - 08/12/24 07:24:08 - 0:00:03 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:09 - 0:00:04 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:09 - 0:00:04 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:09 - 0:00:04 - Test:\tTime 0.383\tLoss 1.4267\tAcc@1 35.294\tBest Acc@1 so far 35.3\n",
            "INFO - 08/12/24 07:24:09 - 0:00:04 - ============ Starting epoch 1 ... ============\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "INFO - 08/12/24 07:24:10 - 0:00:05 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:10 - 0:00:05 - Epoch[1] - Iter: [0/2]\tTime 0.727 (0.727)\tData 0.649 (0.649)\tLoss 1.5049 (1.5049)\tPrec 31.250 (31.250)\tLR 0.2999259840548597\n",
            "INFO - 08/12/24 07:24:10 - 0:00:05 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:11 - 0:00:06 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:11 - 0:00:06 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:12 - 0:00:06 - Test:\tTime 0.572\tLoss 0.8434\tAcc@1 73.529\tBest Acc@1 so far 73.5\n",
            "INFO - 08/12/24 07:24:12 - 0:00:06 - ============ Starting epoch 2 ... ============\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "INFO - 08/12/24 07:24:13 - 0:00:07 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:13 - 0:00:07 - Epoch[2] - Iter: [0/2]\tTime 0.973 (0.973)\tData 0.888 (0.888)\tLoss 0.8165 (0.8165)\tPrec 75.000 (75.000)\tLR 0.29970400926424073\n",
            "INFO - 08/12/24 07:24:13 - 0:00:07 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:14 - 0:00:08 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:14 - 0:00:09 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:14 - 0:00:09 - Test:\tTime 0.560\tLoss 0.5987\tAcc@1 76.471\tBest Acc@1 so far 76.5\n",
            "INFO - 08/12/24 07:24:14 - 0:00:09 - ============ Starting epoch 3 ... ============\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "INFO - 08/12/24 07:24:15 - 0:00:09 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:15 - 0:00:10 - Epoch[3] - Iter: [0/2]\tTime 0.819 (0.819)\tData 0.738 (0.738)\tLoss 0.5047 (0.5047)\tPrec 81.250 (81.250)\tLR 0.299334294690462\n",
            "INFO - 08/12/24 07:24:15 - 0:00:10 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:16 - 0:00:10 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:16 - 0:00:10 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:16 - 0:00:11 - Test:\tTime 0.389\tLoss 0.8926\tAcc@1 61.765\tBest Acc@1 so far 76.5\n",
            "INFO - 08/12/24 07:24:16 - 0:00:11 - ============ Starting epoch 4 ... ============\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "INFO - 08/12/24 07:24:16 - 0:00:11 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:16 - 0:00:11 - Epoch[4] - Iter: [0/2]\tTime 0.643 (0.643)\tData 0.563 (0.563)\tLoss 0.8684 (0.8684)\tPrec 56.250 (56.250)\tLR 0.2988172051971717\n",
            "INFO - 08/12/24 07:24:16 - 0:00:11 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:17 - 0:00:12 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:17 - 0:00:12 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:17 - 0:00:12 - Test:\tTime 0.393\tLoss 0.9938\tAcc@1 73.529\tBest Acc@1 so far 76.5\n",
            "INFO - 08/12/24 07:24:17 - 0:00:12 - ============ Starting epoch 5 ... ============\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "INFO - 08/12/24 07:24:18 - 0:00:13 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:18 - 0:00:13 - Epoch[5] - Iter: [0/2]\tTime 0.649 (0.649)\tData 0.569 (0.569)\tLoss 1.0060 (1.0060)\tPrec 71.875 (71.875)\tLR 0.29815325108927065\n",
            "INFO - 08/12/24 07:24:18 - 0:00:13 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:19 - 0:00:14 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:19 - 0:00:14 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:19 - 0:00:14 - Test:\tTime 0.405\tLoss 0.8110\tAcc@1 76.471\tBest Acc@1 so far 76.5\n",
            "INFO - 08/12/24 07:24:19 - 0:00:14 - ============ Starting epoch 6 ... ============\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "INFO - 08/12/24 07:24:20 - 0:00:14 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:20 - 0:00:14 - Epoch[6] - Iter: [0/2]\tTime 0.662 (0.662)\tData 0.581 (0.581)\tLoss 0.7547 (0.7547)\tPrec 75.000 (75.000)\tLR 0.29734308760930334\n",
            "INFO - 08/12/24 07:24:20 - 0:00:15 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:21 - 0:00:15 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:21 - 0:00:15 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:21 - 0:00:16 - Test:\tTime 0.447\tLoss 0.4674\tAcc@1 82.353\tBest Acc@1 so far 82.4\n",
            "INFO - 08/12/24 07:24:21 - 0:00:16 - ============ Starting epoch 7 ... ============\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "INFO - 08/12/24 07:24:21 - 0:00:16 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:22 - 0:00:16 - Epoch[7] - Iter: [0/2]\tTime 0.690 (0.690)\tData 0.579 (0.579)\tLoss 0.3910 (0.3910)\tPrec 78.125 (78.125)\tLR 0.2963875142908121\n",
            "INFO - 08/12/24 07:24:22 - 0:00:16 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:22 - 0:00:17 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:23 - 0:00:17 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:23 - 0:00:17 - Test:\tTime 0.408\tLoss 0.2881\tAcc@1 91.176\tBest Acc@1 so far 91.2\n",
            "INFO - 08/12/24 07:24:23 - 0:00:17 - ============ Starting epoch 8 ... ============\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1329, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1285, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1133, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.10/queue.py\", line 180, in get\n",
            "    self.not_empty.wait(remaining)\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 324, in wait\n",
            "    gotit = waiter.acquire(True, timeout)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/swav/eval_linear_no_distribution.py\", line 362, in <module>\n",
            "    main()\n",
            "  File \"/content/swav/eval_linear_no_distribution.py\", line 180, in main\n",
            "    scores = train(model, linear_classifier, optimizer, train_loader, epoch)\n",
            "  File \"/content/swav/eval_linear_no_distribution.py\", line 257, in train\n",
            "    for iter_epoch, (inp, target) in enumerate(loader):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 627, in __next__\n",
            "    with torch.autograd.profiler.record_function(self._profile_name):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/profiler.py\", line 620, in __exit__\n",
            "    if not torch.jit.is_scripting():\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_jit_internal.py\", line 1120, in is_scripting\n",
            "    def is_scripting() -> bool:\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy final modifications into our Google Drive files"
      ],
      "metadata": {
        "id": "od5952VUIRTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -f /content/swav/eval_linear_no_distribution.py /content/drive/MyDrive/PLAEX/Selfsupervised_models/swav/code/\n",
        "!cp -f /content/swav/src/utils.py /content/drive/MyDrive/PLAEX/Selfsupervised_models/swav/code/\n"
      ],
      "metadata": {
        "id": "eupFqopajQDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Given time limitation (<1h) in COLAB we are going to try to train locally**\n",
        "- Graph cards: GTX 1060 Ti\n",
        "- RAM: 16GB"
      ],
      "metadata": {
        "id": "slv-93R-r0gR"
      }
    }
  ]
}