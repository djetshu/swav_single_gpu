{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piGkejfKcahG"
      },
      "source": [
        "# SwAv - Unsupervised Learning of Visual Features by Contrasting Cluster Assignments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3WV5xyBc4bC"
      },
      "source": [
        "## 0. Current Colab's Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "s8WY9feLb-U2",
        "outputId": "a754fc9b-6098-4da2-b850-f05eb49fd6c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.__version__\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeM2pwz-nvJm",
        "outputId": "1ff85975-1f45-4615-ea64-6a217b132a82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.10.14\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhoFi2wdcNdg",
        "outputId": "a6dee59a-461b-49e2-8caf-1141c3f9105d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Aug 14 11:09:19 2024       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce GTX 1060 ...    Off |   00000000:01:00.0 Off |                  N/A |\n",
            "| N/A   62C    P5             12W /   70W |     418MiB /   6144MiB |     28%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A      2055      G   /usr/lib/xorg/Xorg                            131MiB |\n",
            "|    0   N/A  N/A      2370      G   /usr/bin/gnome-shell                           22MiB |\n",
            "|    0   N/A  N/A      3896      G   ...irefox/4698/usr/lib/firefox/firefox        154MiB |\n",
            "|    0   N/A  N/A      4897      G   ...erProcess --variations-seed-version        102MiB |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEI5LsxHcHRE",
        "outputId": "da127cfb-cfab-455f-8238-863fa9786c43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwrQuNildFnn"
      },
      "source": [
        "## 1. Initial Setup\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpkqzI7AFLSL"
      },
      "source": [
        "### 1.1. Clonning the repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJaeJ6GIbVxo",
        "outputId": "aa21dabf-f30b-4235-ca5d-091853bd8760"
      },
      "outputs": [],
      "source": [
        "#%cd /content\n",
        "#!git clone https://github.com/facebookresearch/swav.git\n",
        "\n",
        "# THE REPO IS ALREADY CLONNED"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et2LhfBcdKZH"
      },
      "source": [
        "### 1.2. Mounting Google Drives Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZJ8dYGtMlk-",
        "outputId": "ddcd03dd-3464-4f2d-c9e9-c8579304bc04"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "# WE ARE NOT IN COLAB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kjiAlJdFZSn"
      },
      "source": [
        "### 1.3. Set environments variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svBgf3qkNErg",
        "outputId": "507d7596-e90b-4d52-bb86-178d106b8735"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: EXPERIMENT_PATH=/home/jetshu/Documents/PLAEX/code/SwAV/swav_single_gpu/experiments/swav_400ep_bs256_pretrain\n",
            "env: DATASET_PATH=/home/jetshu/Documents/PLAEX/code/PLAEXDatabaseManager/SimplerDataset\n",
            "env: TRAIN_DATASET_PATH=/home/jetshu/Documents/PLAEX/code/PLAEXDatabaseManager/SimplerDataset/train\n",
            "env: VAL_DATASET_PATH=/home/jetshu/Documents/PLAEX/code/PLAEXDatabaseManager/SimplerDataset/val\n",
            "env: TEST_DATASET_PATH=/home/jetshu/Documents/PLAEX/code/PLAEXDatabaseManager/SimplerDataset/test\n"
          ]
        }
      ],
      "source": [
        "%env EXPERIMENT_PATH=/home/jetshu/Documents/PLAEX/code/SwAV/swav_single_gpu/experiments/swav_400ep_bs256_pretrain\n",
        "%env DATASET_PATH=/home/jetshu/Documents/PLAEX/code/PLAEXDatabaseManager/SimplerDataset\n",
        "%env TRAIN_DATASET_PATH=/home/jetshu/Documents/PLAEX/code/PLAEXDatabaseManager/SimplerDataset/train\n",
        "%env VAL_DATASET_PATH=/home/jetshu/Documents/PLAEX/code/PLAEXDatabaseManager/SimplerDataset/val\n",
        "%env TEST_DATASET_PATH=/home/jetshu/Documents/PLAEX/code/PLAEXDatabaseManager/SimplerDataset/test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3g4r2YVHYnn"
      },
      "source": [
        "### 1.4. Check if Dataset and Environment paths exist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOwsKqQSL491",
        "outputId": "3ca7591e-6c0f-4afb-92b7-73cd7224b16d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The directory '/home/jetshu/Documents/PLAEX/code/SwAV/swav_single_gpu/experiments/swav_400ep_bs256_pretrain' exists.\n",
            "The directory '/home/jetshu/Documents/PLAEX/code/PLAEXDatabaseManager/SimplerDataset' exists.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# For EXPERIMENT_PATH\n",
        "dir_path = os.getenv('EXPERIMENT_PATH')\n",
        "if os.path.exists(dir_path):\n",
        "    print(f\"The directory '{dir_path}' exists.\")\n",
        "else:\n",
        "    os.makedirs(dir_path, exist_ok=True)\n",
        "    print(f\"Directory '{dir_path}' created successfully.\")\n",
        "\n",
        "# For DATASET_PATH\n",
        "dataset_path = os.getenv('DATASET_PATH') \n",
        "# Check if the directory exists\n",
        "if os.path.exists(dataset_path):\n",
        "    print(f\"The directory '{dataset_path}' exists.\")\n",
        "else:\n",
        "    print(f\"The directory '{dataset_path}' does not exist.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXvPnKRXHM50"
      },
      "source": [
        "### 1.5. Copy our modificated codes to SwAV repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pkw8VC7IK1qk"
      },
      "outputs": [],
      "source": [
        "#!cp /content/drive/MyDrive/PLAEX/Selfsupervised_models/swav/code/main_swav_no_apex.py /content/swav/\n",
        "#!cp -f /content/drive/MyDrive/PLAEX/Selfsupervised_models/swav/code/utils.py /content/swav/src/\n",
        "#!cp /content/drive/MyDrive/PLAEX/Selfsupervised_models/swav/code/eval_linear_no_distribution.py /content/swav/\n",
        "\n",
        "# NOT NECESSARY IN LOCAL PC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwbAzy3TFfSp"
      },
      "source": [
        "## 2. Training and Evaluating SwAV\n",
        "The training is divided into 2 main steps:\n",
        "\n",
        "\n",
        "*   Self supervised training of SwAV model: In order to cluster the features of the images. But not predicting the classification as paper, plastic, etc.\n",
        "*   Supervised Linear Classification training on top of SwaV: After getting the cluster of the features is necessary to classify them into the label that we want as paper, plastic, etc.\n",
        "\n",
        "This process is common on this type of classification task in selfsupervised models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeKeoSZDG0dn"
      },
      "source": [
        "### 2.1. Self supervised training of SwAV model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wnLDoiH-apt",
        "outputId": "1a3fa7e6-1d3d-4280-fd0c-7295f9d50b39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/jetshu/Documents/PLAEX/code/SwAV/swav_single_gpu\n",
            "INFO - 08/14/24 11:10:05 - 0:00:00 - ============ Initialized logger ============\n",
            "INFO - 08/14/24 11:10:05 - 0:00:00 - arch: resnet50\n",
            "                                     base_lr: 0.6\n",
            "                                     batch_size: 16\n",
            "                                     checkpoint_freq: 25\n",
            "                                     crops_for_assign: [0, 1]\n",
            "                                     data_path: /home/jetshu/Documents/PLAEX/code/PLAEXDatabaseManager/SimplerDataset/train\n",
            "                                     dump_checkpoints: /home/jetshu/Documents/PLAEX/code/SwAV/swav_single_gpu/experiments/swav_400ep_bs256_pretrain/checkpoints\n",
            "                                     dump_path: /home/jetshu/Documents/PLAEX/code/SwAV/swav_single_gpu/experiments/swav_400ep_bs256_pretrain\n",
            "                                     epoch_queue_starts: 15\n",
            "                                     epochs: 15\n",
            "                                     epsilon: 0.05\n",
            "                                     feat_dim: 128\n",
            "                                     final_lr: 0.0006\n",
            "                                     freeze_prototypes_niters: 5005\n",
            "                                     hidden_mlp: 2048\n",
            "                                     max_scale_crops: [1.0, 0.14]\n",
            "                                     min_scale_crops: [0.14, 0.05]\n",
            "                                     nmb_crops: [2, 6]\n",
            "                                     nmb_prototypes: 3000\n",
            "                                     queue_length: 3840\n",
            "                                     seed: 31\n",
            "                                     sinkhorn_iterations: 3\n",
            "                                     size_crops: [224, 96]\n",
            "                                     start_warmup: 0\n",
            "                                     temperature: 0.1\n",
            "                                     use_fp16: True\n",
            "                                     warmup_epochs: 0\n",
            "                                     wd: 1e-06\n",
            "                                     workers: 1\n",
            "INFO - 08/14/24 11:10:05 - 0:00:00 - The experiment will be stored in /home/jetshu/Documents/PLAEX/code/SwAV/swav_single_gpu/experiments/swav_400ep_bs256_pretrain\n",
            "                                     \n",
            "\n",
            "INFO - 08/14/24 11:10:05 - 0:00:00 - Building data done with 14878 images loaded.\n",
            "INFO - 08/14/24 11:10:05 - 0:00:00 - ResNet(\n",
            "                                       (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "                                       (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                       (relu): ReLU(inplace=True)\n",
            "                                       (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "                                       (layer1): Sequential(\n",
            "                                         (0): Bottleneck(\n",
            "                                           (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                           (downsample): Sequential(\n",
            "                                             (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           )\n",
            "                                         )\n",
            "                                         (1): Bottleneck(\n",
            "                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                         )\n",
            "                                         (2): Bottleneck(\n",
            "                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                         )\n",
            "                                       )\n",
            "                                       (layer2): Sequential(\n",
            "                                         (0): Bottleneck(\n",
            "                                           (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                           (downsample): Sequential(\n",
            "                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           )\n",
            "                                         )\n",
            "                                         (1): Bottleneck(\n",
            "                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                         )\n",
            "                                         (2): Bottleneck(\n",
            "                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                         )\n",
            "                                         (3): Bottleneck(\n",
            "                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                         )\n",
            "                                       )\n",
            "                                       (layer3): Sequential(\n",
            "                                         (0): Bottleneck(\n",
            "                                           (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                           (downsample): Sequential(\n",
            "                                             (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "                                             (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           )\n",
            "                                         )\n",
            "                                         (1): Bottleneck(\n",
            "                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                         )\n",
            "                                         (2): Bottleneck(\n",
            "                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                         )\n",
            "                                         (3): Bottleneck(\n",
            "                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                         )\n",
            "                                         (4): Bottleneck(\n",
            "                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                         )\n",
            "                                         (5): Bottleneck(\n",
            "                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                         )\n",
            "                                       )\n",
            "                                       (layer4): Sequential(\n",
            "                                         (0): Bottleneck(\n",
            "                                           (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                           (downsample): Sequential(\n",
            "                                             (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "                                             (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           )\n",
            "                                         )\n",
            "                                         (1): Bottleneck(\n",
            "                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                         )\n",
            "                                         (2): Bottleneck(\n",
            "                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                           (relu): ReLU(inplace=True)\n",
            "                                         )\n",
            "                                       )\n",
            "                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "                                       (projection_head): Sequential(\n",
            "                                         (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "                                         (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                         (2): ReLU(inplace=True)\n",
            "                                         (3): Linear(in_features=2048, out_features=128, bias=True)\n",
            "                                       )\n",
            "                                       (prototypes): Linear(in_features=128, out_features=3000, bias=False)\n",
            "                                     )\n",
            "INFO - 08/14/24 11:10:05 - 0:00:00 - Building model done.\n",
            "INFO - 08/14/24 11:10:05 - 0:00:01 - Building optimizer done.\n",
            "INFO - 08/14/24 11:10:05 - 0:00:01 - Initializing mixed precision done.\n",
            "INFO - 08/14/24 11:10:05 - 0:00:01 - Found checkpoint at /home/jetshu/Documents/PLAEX/code/SwAV/swav_single_gpu/experiments/swav_400ep_bs256_pretrain/swav_400ep_bs256_pretrain.pth.tar\n",
            "INFO - 08/14/24 11:10:05 - 0:00:01 - Loaded model state from checkpoint '/home/jetshu/Documents/PLAEX/code/SwAV/swav_single_gpu/experiments/swav_400ep_bs256_pretrain/swav_400ep_bs256_pretrain.pth.tar'\n",
            "WARNING - 08/14/24 11:10:05 - 0:00:01 - => failed to load optimizer from checkpoint '/home/jetshu/Documents/PLAEX/code/SwAV/swav_single_gpu/experiments/swav_400ep_bs256_pretrain/swav_400ep_bs256_pretrain.pth.tar'\n",
            "INFO - 08/14/24 11:10:05 - 0:00:01 - ============ Starting epoch 0 ... ============\n",
            "INFO - 08/14/24 11:10:35 - 0:00:31 - Epoch: [0][0]\tTime 30.127 (30.127)\tData 0.585 (0.585)\tLoss 8.4504 (8.4504)\tLr: 0.6000\n",
            "INFO - 08/14/24 11:11:15 - 0:01:10 - Epoch: [0][50]\tTime 0.801 (1.370)\tData 0.001 (0.012)\tLoss 8.0289 (8.2736)\tLr: 0.6000\n",
            "INFO - 08/14/24 11:11:57 - 0:01:52 - Epoch: [0][100]\tTime 0.806 (1.105)\tData 0.000 (0.023)\tLoss 8.0099 (8.1472)\tLr: 0.5999\n",
            "INFO - 08/14/24 11:12:37 - 0:02:32 - Epoch: [0][150]\tTime 0.811 (1.006)\tData 0.000 (0.016)\tLoss 8.0099 (8.1019)\tLr: 0.5998\n",
            "INFO - 08/14/24 11:13:37 - 0:03:33 - Epoch: [0][200]\tTime 0.814 (1.056)\tData 0.000 (0.112)\tLoss 8.0083 (8.0788)\tLr: 0.5997\n",
            "INFO - 08/14/24 11:14:42 - 0:04:37 - Epoch: [0][250]\tTime 0.808 (1.101)\tData 0.000 (0.185)\tLoss 8.0083 (8.0648)\tLr: 0.5995\n",
            "INFO - 08/14/24 11:15:48 - 0:05:43 - Epoch: [0][300]\tTime 0.793 (1.139)\tData 0.001 (0.241)\tLoss 8.0075 (8.0553)\tLr: 0.5993\n",
            "INFO - 08/14/24 11:16:53 - 0:06:48 - Epoch: [0][350]\tTime 2.405 (1.161)\tData 1.594 (0.277)\tLoss 8.0071 (8.0485)\tLr: 0.5991\n",
            "INFO - 08/14/24 11:17:45 - 0:07:40 - Epoch: [0][400]\tTime 2.564 (1.147)\tData 1.744 (0.273)\tLoss 8.0071 (8.0434)\tLr: 0.5988\n",
            "INFO - 08/14/24 11:18:45 - 0:08:41 - Epoch: [0][450]\tTime 0.795 (1.153)\tData 0.000 (0.288)\tLoss 8.0072 (8.0394)\tLr: 0.5985\n",
            "INFO - 08/14/24 11:19:58 - 0:09:53 - Epoch: [0][500]\tTime 0.797 (1.183)\tData 0.000 (0.323)\tLoss 8.0072 (8.0361)\tLr: 0.5981\n",
            "INFO - 08/14/24 11:21:11 - 0:11:06 - Epoch: [0][550]\tTime 0.800 (1.208)\tData 0.000 (0.353)\tLoss 8.0071 (8.0335)\tLr: 0.5977\n",
            "INFO - 08/14/24 11:22:21 - 0:12:17 - Epoch: [0][600]\tTime 4.507 (1.225)\tData 3.665 (0.375)\tLoss 8.0069 (8.0313)\tLr: 0.5973\n",
            "INFO - 08/14/24 11:23:29 - 0:13:25 - Epoch: [0][650]\tTime 4.217 (1.235)\tData 3.393 (0.390)\tLoss 8.0070 (8.0295)\tLr: 0.5968\n",
            "INFO - 08/14/24 11:24:36 - 0:14:32 - Epoch: [0][700]\tTime 2.915 (1.243)\tData 2.161 (0.401)\tLoss 8.0069 (8.0279)\tLr: 0.5963\n",
            "INFO - 08/14/24 11:25:27 - 0:15:22 - Epoch: [0][750]\tTime 0.758 (1.227)\tData 0.000 (0.391)\tLoss 8.0071 (8.0265)\tLr: 0.5957\n",
            "INFO - 08/14/24 11:26:38 - 0:16:33 - Epoch: [0][800]\tTime 0.781 (1.240)\tData 0.000 (0.407)\tLoss 8.0068 (8.0253)\tLr: 0.5951\n",
            "INFO - 08/14/24 11:27:48 - 0:17:43 - Epoch: [0][850]\tTime 0.794 (1.249)\tData 0.000 (0.419)\tLoss 8.0068 (8.0242)\tLr: 0.5945\n",
            "INFO - 08/14/24 11:28:59 - 0:18:54 - Epoch: [0][900]\tTime 0.804 (1.258)\tData 0.000 (0.430)\tLoss 8.0069 (8.0232)\tLr: 0.5939\n",
            "INFO - 08/14/24 11:29:38 - 0:19:33 - ============ Starting epoch 1 ... ============\n",
            "INFO - 08/14/24 11:29:41 - 0:19:36 - Epoch: [1][0]\tTime 3.144 (3.144)\tData 2.310 (2.310)\tLoss 8.0069 (8.0069)\tLr: 0.5935\n",
            "INFO - 08/14/24 11:30:33 - 0:20:28 - Epoch: [1][50]\tTime 0.806 (1.081)\tData 0.000 (0.278)\tLoss 8.0068 (8.0068)\tLr: 0.5927\n",
            "INFO - 08/14/24 11:31:41 - 0:21:36 - Epoch: [1][100]\tTime 0.821 (1.219)\tData 0.000 (0.415)\tLoss 8.0069 (8.0068)\tLr: 0.5920\n",
            "INFO - 08/14/24 11:32:50 - 0:22:45 - Epoch: [1][150]\tTime 0.805 (1.274)\tData 0.001 (0.469)\tLoss 8.0070 (8.0068)\tLr: 0.5912\n",
            "INFO - 08/14/24 11:33:57 - 0:23:52 - Epoch: [1][200]\tTime 2.159 (1.291)\tData 1.357 (0.486)\tLoss 8.0067 (8.0068)\tLr: 0.5903\n",
            "INFO - 08/14/24 11:34:37 - 0:24:33 - Epoch: [1][250]\tTime 0.820 (1.194)\tData 0.001 (0.389)\tLoss 8.0067 (8.0068)\tLr: 0.5895\n",
            "INFO - 08/14/24 11:35:42 - 0:25:37 - Epoch: [1][300]\tTime 0.831 (1.210)\tData 0.000 (0.403)\tLoss 8.0066 (8.0068)\tLr: 0.5886\n",
            "INFO - 08/14/24 11:36:53 - 0:26:48 - Epoch: [1][350]\tTime 0.835 (1.241)\tData 0.000 (0.430)\tLoss 8.0066 (8.0068)\tLr: 0.5876\n",
            "INFO - 08/14/24 11:37:59 - 0:27:54 - Epoch: [1][400]\tTime 0.794 (1.249)\tData 0.001 (0.437)\tLoss 8.0066 (8.0068)\tLr: 0.5866\n",
            "INFO - 08/14/24 11:38:54 - 0:28:50 - Epoch: [1][450]\tTime 2.401 (1.235)\tData 1.587 (0.423)\tLoss 8.0066 (8.0068)\tLr: 0.5856\n",
            "INFO - 08/14/24 11:39:45 - 0:29:40 - Epoch: [1][500]\tTime 0.804 (1.212)\tData 0.000 (0.402)\tLoss 8.0069 (8.0067)\tLr: 0.5846\n",
            "INFO - 08/14/24 11:40:49 - 0:30:45 - Epoch: [1][550]\tTime 0.818 (1.219)\tData 0.000 (0.409)\tLoss 8.0066 (8.0067)\tLr: 0.5835\n",
            "INFO - 08/14/24 11:41:55 - 0:31:50 - Epoch: [1][600]\tTime 0.796 (1.227)\tData 0.000 (0.417)\tLoss 8.0066 (8.0067)\tLr: 0.5824\n",
            "INFO - 08/14/24 11:43:00 - 0:32:55 - Epoch: [1][650]\tTime 0.900 (1.233)\tData 0.112 (0.423)\tLoss 8.0066 (8.0067)\tLr: 0.5812\n",
            "INFO - 08/14/24 11:43:43 - 0:33:38 - Epoch: [1][700]\tTime 2.765 (1.206)\tData 1.960 (0.396)\tLoss 8.0066 (8.0067)\tLr: 0.5800\n",
            "INFO - 08/14/24 11:44:44 - 0:34:39 - Epoch: [1][750]\tTime 0.798 (1.207)\tData 0.000 (0.398)\tLoss 8.0068 (8.0067)\tLr: 0.5788\n",
            "INFO - 08/14/24 11:45:47 - 0:35:42 - Epoch: [1][800]\tTime 0.799 (1.210)\tData 0.001 (0.402)\tLoss 8.0066 (8.0067)\tLr: 0.5775\n",
            "INFO - 08/14/24 11:46:51 - 0:36:46 - Epoch: [1][850]\tTime 0.800 (1.214)\tData 0.000 (0.406)\tLoss 8.0066 (8.0067)\tLr: 0.5762\n",
            "INFO - 08/14/24 11:47:53 - 0:37:48 - Epoch: [1][900]\tTime 1.581 (1.216)\tData 0.785 (0.408)\tLoss 8.0066 (8.0067)\tLr: 0.5749\n",
            "INFO - 08/14/24 11:48:17 - 0:38:12 - ============ Starting epoch 2 ... ============\n",
            "INFO - 08/14/24 11:48:18 - 0:38:13 - Epoch: [2][0]\tTime 1.288 (1.288)\tData 0.486 (0.486)\tLoss 8.0065 (8.0065)\tLr: 0.5741\n",
            "INFO - 08/14/24 11:49:21 - 0:39:17 - Epoch: [2][50]\tTime 0.807 (1.271)\tData 0.000 (0.468)\tLoss 8.0066 (8.0066)\tLr: 0.5727\n",
            "INFO - 08/14/24 11:50:25 - 0:40:20 - Epoch: [2][100]\tTime 0.802 (1.270)\tData 0.000 (0.467)\tLoss 8.0066 (8.0066)\tLr: 0.5713\n",
            "INFO - 08/14/24 11:51:19 - 0:41:15 - Epoch: [2][150]\tTime 2.680 (1.210)\tData 1.874 (0.406)\tLoss 8.0067 (8.0066)\tLr: 0.5698\n",
            "INFO - 08/14/24 11:52:08 - 0:42:04 - Epoch: [2][200]\tTime 0.813 (1.153)\tData 0.001 (0.349)\tLoss 8.0066 (8.0066)\tLr: 0.5683\n",
            "INFO - 08/14/24 11:53:10 - 0:43:05 - Epoch: [2][250]\tTime 0.796 (1.167)\tData 0.000 (0.364)\tLoss 8.0065 (8.0066)\tLr: 0.5668\n",
            "INFO - 08/14/24 11:54:11 - 0:44:06 - Epoch: [2][300]\tTime 0.798 (1.178)\tData 0.000 (0.374)\tLoss 8.0065 (8.0066)\tLr: 0.5652\n",
            "INFO - 08/14/24 11:55:13 - 0:45:08 - Epoch: [2][350]\tTime 0.790 (1.186)\tData 0.000 (0.382)\tLoss 8.0065 (8.0066)\tLr: 0.5636\n",
            "INFO - 08/14/24 11:55:56 - 0:45:51 - Epoch: [2][400]\tTime 2.504 (1.145)\tData 1.701 (0.341)\tLoss 8.0065 (8.0066)\tLr: 0.5620\n",
            "INFO - 08/14/24 11:56:58 - 0:46:53 - Epoch: [2][450]\tTime 0.807 (1.156)\tData 0.000 (0.352)\tLoss 8.0065 (8.0066)\tLr: 0.5603\n",
            "INFO - 08/14/24 11:58:02 - 0:47:57 - Epoch: [2][500]\tTime 0.795 (1.168)\tData 0.000 (0.364)\tLoss 8.0067 (8.0066)\tLr: 0.5586\n",
            "INFO - 08/14/24 11:59:02 - 0:48:58 - Epoch: [2][550]\tTime 0.792 (1.172)\tData 0.000 (0.368)\tLoss 8.0065 (8.0066)\tLr: 0.5569\n",
            "INFO - 08/14/24 11:59:57 - 0:49:53 - Epoch: [2][600]\tTime 4.045 (1.166)\tData 3.242 (0.362)\tLoss 8.0065 (8.0066)\tLr: 0.5551\n",
            "INFO - 08/14/24 12:00:44 - 0:50:39 - Epoch: [2][650]\tTime 1.028 (1.148)\tData 0.230 (0.345)\tLoss 8.0065 (8.0066)\tLr: 0.5534\n",
            "INFO - 08/14/24 12:01:47 - 0:51:42 - Epoch: [2][700]\tTime 0.808 (1.155)\tData 0.000 (0.352)\tLoss 8.0065 (8.0066)\tLr: 0.5515\n",
            "INFO - 08/14/24 12:02:49 - 0:52:44 - Epoch: [2][750]\tTime 0.793 (1.161)\tData 0.000 (0.357)\tLoss 8.0066 (8.0066)\tLr: 0.5497\n",
            "INFO - 08/14/24 12:03:50 - 0:53:45 - Epoch: [2][800]\tTime 0.792 (1.165)\tData 0.000 (0.361)\tLoss 8.0066 (8.0066)\tLr: 0.5478\n",
            "INFO - 08/14/24 12:04:43 - 0:54:38 - Epoch: [2][850]\tTime 2.344 (1.159)\tData 1.521 (0.355)\tLoss 8.0066 (8.0066)\tLr: 0.5459\n",
            "INFO - 08/14/24 12:05:30 - 0:55:25 - Epoch: [2][900]\tTime 0.804 (1.147)\tData 0.000 (0.343)\tLoss 8.0065 (8.0066)\tLr: 0.5439\n",
            "INFO - 08/14/24 12:06:14 - 0:56:10 - ============ Starting epoch 3 ... ============\n",
            "INFO - 08/14/24 12:06:16 - 0:56:11 - Epoch: [3][0]\tTime 1.300 (1.300)\tData 0.493 (0.493)\tLoss 8.0066 (8.0066)\tLr: 0.5428\n",
            "INFO - 08/14/24 12:07:08 - 0:57:03 - Epoch: [3][50]\tTime 2.443 (1.054)\tData 1.632 (0.247)\tLoss 8.0065 (8.0065)\tLr: 0.5408\n",
            "INFO - 08/14/24 12:08:00 - 0:57:55 - Epoch: [3][100]\tTime 0.802 (1.045)\tData 0.000 (0.241)\tLoss 8.0065 (8.0065)\tLr: 0.5387\n",
            "INFO - 08/14/24 12:09:04 - 0:58:59 - Epoch: [3][150]\tTime 0.805 (1.121)\tData 0.000 (0.316)\tLoss 8.0066 (8.0065)\tLr: 0.5367\n",
            "INFO - 08/14/24 12:10:08 - 1:00:04 - Epoch: [3][200]\tTime 0.799 (1.165)\tData 0.000 (0.360)\tLoss 8.0065 (8.0066)\tLr: 0.5346\n",
            "INFO - 08/14/24 12:10:57 - 1:00:53 - Epoch: [3][250]\tTime 2.475 (1.128)\tData 1.657 (0.323)\tLoss 8.0065 (8.0066)\tLr: 0.5325\n",
            "INFO - 08/14/24 12:11:49 - 1:01:45 - Epoch: [3][300]\tTime 0.796 (1.113)\tData 0.000 (0.309)\tLoss 8.0066 (8.0066)\tLr: 0.5303\n",
            "INFO - 08/14/24 12:12:50 - 1:02:46 - Epoch: [3][350]\tTime 0.797 (1.129)\tData 0.000 (0.324)\tLoss 8.0065 (8.0065)\tLr: 0.5281\n",
            "INFO - 08/14/24 12:13:51 - 1:03:46 - Epoch: [3][400]\tTime 0.796 (1.139)\tData 0.000 (0.334)\tLoss 8.0065 (8.0065)\tLr: 0.5259\n",
            "INFO - 08/14/24 12:14:52 - 1:04:47 - Epoch: [3][450]\tTime 0.798 (1.148)\tData 0.000 (0.343)\tLoss 8.0065 (8.0065)\tLr: 0.5237\n",
            "INFO - 08/14/24 12:15:39 - 1:05:34 - Epoch: [3][500]\tTime 2.667 (1.127)\tData 1.866 (0.323)\tLoss 8.0065 (8.0065)\tLr: 0.5214\n",
            "INFO - 08/14/24 12:16:36 - 1:06:31 - Epoch: [3][550]\tTime 0.801 (1.128)\tData 0.000 (0.324)\tLoss 8.0065 (8.0065)\tLr: 0.5191\n",
            "INFO - 08/14/24 12:17:38 - 1:07:34 - Epoch: [3][600]\tTime 0.797 (1.138)\tData 0.000 (0.334)\tLoss 8.0065 (8.0065)\tLr: 0.5168\n",
            "INFO - 08/14/24 12:18:47 - 1:08:42 - Epoch: [3][650]\tTime 1.084 (1.156)\tData 0.289 (0.351)\tLoss 8.0065 (8.0065)\tLr: 0.5144\n",
            "INFO - 08/14/24 12:19:39 - 1:09:35 - Epoch: [3][700]\tTime 2.891 (1.148)\tData 2.071 (0.344)\tLoss 8.0065 (8.0065)\tLr: 0.5121\n",
            "INFO - 08/14/24 12:20:28 - 1:10:23 - Epoch: [3][750]\tTime 0.803 (1.137)\tData 0.001 (0.333)\tLoss 8.0066 (8.0065)\tLr: 0.5097\n",
            "INFO - 08/14/24 12:21:33 - 1:11:28 - Epoch: [3][800]\tTime 0.799 (1.147)\tData 0.000 (0.343)\tLoss 8.0065 (8.0065)\tLr: 0.5072\n",
            "INFO - 08/14/24 12:22:38 - 1:12:33 - Epoch: [3][850]\tTime 0.804 (1.156)\tData 0.000 (0.352)\tLoss 8.0065 (8.0065)\tLr: 0.5048\n",
            "INFO - 08/14/24 12:23:41 - 1:13:36 - Epoch: [3][900]\tTime 0.801 (1.162)\tData 0.001 (0.358)\tLoss 8.0065 (8.0065)\tLr: 0.5023\n",
            "INFO - 08/14/24 12:24:04 - 1:13:59 - ============ Starting epoch 4 ... ============\n",
            "INFO - 08/14/24 12:24:05 - 1:14:00 - Epoch: [4][0]\tTime 1.293 (1.293)\tData 0.479 (0.479)\tLoss 8.0065 (8.0065)\tLr: 0.5008\n",
            "INFO - 08/14/24 12:25:10 - 1:15:05 - Epoch: [4][50]\tTime 0.805 (1.300)\tData 0.000 (0.494)\tLoss 8.0065 (8.0065)\tLr: 0.4983\n",
            "INFO - 08/14/24 12:26:17 - 1:16:12 - Epoch: [4][100]\tTime 0.804 (1.318)\tData 0.000 (0.512)\tLoss 8.0065 (8.0065)\tLr: 0.4958\n",
            "INFO - 08/14/24 12:27:18 - 1:17:13 - Epoch: [4][150]\tTime 2.854 (1.285)\tData 2.042 (0.480)\tLoss 8.0065 (8.0065)\tLr: 0.4932\n",
            "INFO - 08/14/24 12:28:03 - 1:17:58 - Epoch: [4][200]\tTime 0.798 (1.189)\tData 0.000 (0.384)\tLoss 8.0065 (8.0065)\tLr: 0.4906\n",
            "INFO - 08/14/24 12:29:05 - 1:19:01 - Epoch: [4][250]\tTime 0.797 (1.201)\tData 0.000 (0.397)\tLoss 8.0065 (8.0065)\tLr: 0.4880\n",
            "INFO - 08/14/24 12:30:07 - 1:20:02 - Epoch: [4][300]\tTime 0.802 (1.207)\tData 0.000 (0.402)\tLoss 8.0065 (8.0065)\tLr: 0.4853\n",
            "INFO - 08/14/24 12:31:11 - 1:21:07 - Epoch: [4][350]\tTime 0.791 (1.218)\tData 0.000 (0.413)\tLoss 8.0065 (8.0065)\tLr: 0.4827\n",
            "INFO - 08/14/24 12:32:13 - 1:22:09 - Epoch: [4][400]\tTime 1.788 (1.221)\tData 0.991 (0.416)\tLoss 8.0064 (8.0065)\tLr: 0.4800\n",
            "INFO - 08/14/24 12:32:53 - 1:22:49 - Epoch: [4][450]\tTime 0.810 (1.174)\tData 0.000 (0.370)\tLoss 8.0064 (8.0065)\tLr: 0.4773\n",
            "INFO - 08/14/24 12:33:56 - 1:23:51 - Epoch: [4][500]\tTime 0.803 (1.181)\tData 0.000 (0.377)\tLoss 8.0065 (8.0065)\tLr: 0.4745\n",
            "INFO - 08/14/24 12:34:59 - 1:24:54 - Epoch: [4][550]\tTime 0.802 (1.189)\tData 0.000 (0.384)\tLoss 8.0065 (8.0065)\tLr: 0.4718\n",
            "INFO - 08/14/24 12:36:02 - 1:25:57 - Epoch: [4][600]\tTime 0.807 (1.195)\tData 0.001 (0.390)\tLoss 8.0065 (8.0065)\tLr: 0.4690\n",
            "INFO - 08/14/24 12:37:08 - 1:27:03 - Epoch: [4][650]\tTime 0.886 (1.204)\tData 0.094 (0.399)\tLoss 8.0065 (8.0065)\tLr: 0.4662\n",
            "INFO - 08/14/24 12:37:55 - 1:27:51 - Epoch: [4][700]\tTime 2.819 (1.186)\tData 2.006 (0.382)\tLoss 8.0065 (8.0065)\tLr: 0.4633\n",
            "INFO - 08/14/24 12:38:51 - 1:28:46 - Epoch: [4][750]\tTime 0.802 (1.181)\tData 0.000 (0.377)\tLoss 8.0065 (8.0065)\tLr: 0.4605\n",
            "INFO - 08/14/24 12:39:57 - 1:29:53 - Epoch: [4][800]\tTime 0.795 (1.191)\tData 0.000 (0.386)\tLoss 8.0064 (8.0065)\tLr: 0.4576\n",
            "INFO - 08/14/24 12:41:02 - 1:30:57 - Epoch: [4][850]\tTime 0.804 (1.197)\tData 0.000 (0.392)\tLoss 8.0065 (8.0065)\tLr: 0.4547\n",
            "INFO - 08/14/24 12:41:57 - 1:31:53 - Epoch: [4][900]\tTime 1.635 (1.192)\tData 0.816 (0.387)\tLoss 8.0065 (8.0065)\tLr: 0.4518\n",
            "INFO - 08/14/24 12:42:30 - 1:32:25 - ============ Starting epoch 5 ... ============\n",
            "INFO - 08/14/24 12:42:31 - 1:32:27 - Epoch: [5][0]\tTime 1.348 (1.348)\tData 0.533 (0.533)\tLoss 8.0065 (8.0065)\tLr: 0.4501\n",
            "INFO - 08/14/24 12:43:34 - 1:33:30 - Epoch: [5][50]\tTime 0.809 (1.260)\tData 0.000 (0.453)\tLoss 8.0065 (8.0065)\tLr: 0.4472\n",
            "INFO - 08/14/24 12:44:30 - 1:34:25 - Epoch: [5][100]\tTime 1.565 (1.186)\tData 0.750 (0.383)\tLoss 8.0064 (8.0065)\tLr: 0.4443\n",
            "INFO - 08/14/24 12:45:17 - 1:35:12 - Epoch: [5][150]\tTime 0.808 (1.106)\tData 0.000 (0.304)\tLoss 8.0066 (8.0065)\tLr: 0.4413\n",
            "INFO - 08/14/24 12:46:19 - 1:36:14 - Epoch: [5][200]\tTime 0.805 (1.138)\tData 0.000 (0.335)\tLoss 8.0065 (8.0065)\tLr: 0.4383\n",
            "INFO - 08/14/24 12:47:22 - 1:37:17 - Epoch: [5][250]\tTime 0.805 (1.163)\tData 0.000 (0.360)\tLoss 8.0065 (8.0065)\tLr: 0.4353\n",
            "INFO - 08/14/24 12:48:25 - 1:38:20 - Epoch: [5][300]\tTime 0.806 (1.180)\tData 0.000 (0.376)\tLoss 8.0065 (8.0065)\tLr: 0.4323\n",
            "INFO - 08/14/24 12:49:26 - 1:39:21 - Epoch: [5][350]\tTime 2.390 (1.184)\tData 1.568 (0.380)\tLoss 8.0065 (8.0065)\tLr: 0.4292\n",
            "INFO - 08/14/24 12:50:13 - 1:40:08 - Epoch: [5][400]\tTime 0.806 (1.155)\tData 0.000 (0.351)\tLoss 8.0064 (8.0065)\tLr: 0.4262\n",
            "INFO - 08/14/24 12:51:18 - 1:41:13 - Epoch: [5][450]\tTime 0.795 (1.171)\tData 0.000 (0.367)\tLoss 8.0064 (8.0065)\tLr: 0.4231\n",
            "INFO - 08/14/24 12:52:24 - 1:42:19 - Epoch: [5][500]\tTime 0.798 (1.185)\tData 0.001 (0.381)\tLoss 8.0065 (8.0065)\tLr: 0.4200\n",
            "INFO - 08/14/24 12:53:28 - 1:43:23 - Epoch: [5][550]\tTime 0.924 (1.194)\tData 0.133 (0.390)\tLoss 8.0065 (8.0065)\tLr: 0.4169\n",
            "INFO - 08/14/24 12:54:20 - 1:44:15 - Epoch: [5][600]\tTime 3.950 (1.181)\tData 3.133 (0.377)\tLoss 8.0065 (8.0065)\tLr: 0.4138\n",
            "INFO - 08/14/24 12:55:13 - 1:45:08 - Epoch: [5][650]\tTime 1.303 (1.171)\tData 0.502 (0.368)\tLoss 8.0065 (8.0065)\tLr: 0.4106\n",
            "INFO - 08/14/24 12:56:17 - 1:46:12 - Epoch: [5][700]\tTime 0.801 (1.179)\tData 0.000 (0.375)\tLoss 8.0065 (8.0065)\tLr: 0.4075\n",
            "INFO - 08/14/24 12:57:22 - 1:47:17 - Epoch: [5][750]\tTime 0.813 (1.187)\tData 0.000 (0.383)\tLoss 8.0065 (8.0065)\tLr: 0.4043\n",
            "INFO - 08/14/24 12:58:29 - 1:48:24 - Epoch: [5][800]\tTime 0.807 (1.197)\tData 0.000 (0.393)\tLoss 8.0065 (8.0065)\tLr: 0.4012\n",
            "INFO - 08/14/24 12:59:35 - 1:49:31 - Epoch: [5][850]\tTime 0.799 (1.205)\tData 0.000 (0.401)\tLoss 8.0065 (8.0065)\tLr: 0.3980\n",
            "INFO - 08/14/24 13:00:44 - 1:50:39 - Epoch: [5][900]\tTime 0.799 (1.214)\tData 0.001 (0.410)\tLoss 8.0065 (8.0065)\tLr: 0.3948\n",
            "INFO - 08/14/24 13:01:06 - 1:51:02 - ============ Starting epoch 6 ... ============\n",
            "INFO - 08/14/24 13:01:08 - 1:51:03 - Epoch: [6][0]\tTime 1.306 (1.306)\tData 0.493 (0.493)\tLoss 8.0065 (8.0065)\tLr: 0.3929\n",
            "INFO - 08/14/24 13:02:17 - 1:52:13 - Epoch: [6][50]\tTime 0.802 (1.393)\tData 0.000 (0.588)\tLoss 8.0065 (8.0065)\tLr: 0.3897\n",
            "INFO - 08/14/24 13:03:27 - 1:53:22 - Epoch: [6][100]\tTime 0.800 (1.391)\tData 0.000 (0.586)\tLoss 8.0064 (8.0065)\tLr: 0.3865\n",
            "INFO - 08/14/24 13:04:35 - 1:54:30 - Epoch: [6][150]\tTime 2.844 (1.380)\tData 2.037 (0.575)\tLoss 8.0066 (8.0065)\tLr: 0.3832\n",
            "INFO - 08/14/24 13:05:20 - 1:55:15 - Epoch: [6][200]\tTime 2.765 (1.262)\tData 1.958 (0.458)\tLoss 8.0065 (8.0065)\tLr: 0.3800\n",
            "INFO - 08/14/24 13:06:26 - 1:56:22 - Epoch: [6][250]\tTime 0.808 (1.275)\tData 0.000 (0.471)\tLoss 8.0065 (8.0065)\tLr: 0.3767\n",
            "INFO - 08/14/24 13:07:37 - 1:57:33 - Epoch: [6][300]\tTime 0.795 (1.299)\tData 0.000 (0.494)\tLoss 8.0065 (8.0065)\tLr: 0.3734\n",
            "INFO - 08/14/24 13:08:48 - 1:58:43 - Epoch: [6][350]\tTime 0.794 (1.315)\tData 0.000 (0.511)\tLoss 8.0064 (8.0065)\tLr: 0.3702\n",
            "INFO - 08/14/24 13:09:49 - 1:59:44 - Epoch: [6][400]\tTime 2.352 (1.304)\tData 1.553 (0.499)\tLoss 8.0065 (8.0065)\tLr: 0.3669\n",
            "INFO - 08/14/24 13:10:42 - 2:00:37 - Epoch: [6][450]\tTime 0.799 (1.275)\tData 0.000 (0.472)\tLoss 8.0064 (8.0065)\tLr: 0.3636\n",
            "INFO - 08/14/24 13:11:50 - 2:01:45 - Epoch: [6][500]\tTime 0.795 (1.285)\tData 0.000 (0.481)\tLoss 8.0065 (8.0065)\tLr: 0.3603\n",
            "INFO - 08/14/24 13:13:01 - 2:02:57 - Epoch: [6][550]\tTime 0.791 (1.297)\tData 0.000 (0.494)\tLoss 8.0064 (8.0065)\tLr: 0.3569\n",
            "INFO - 08/14/24 13:14:11 - 2:04:06 - Epoch: [6][600]\tTime 0.867 (1.306)\tData 0.078 (0.502)\tLoss 8.0064 (8.0065)\tLr: 0.3536\n",
            "INFO - 08/14/24 13:15:22 - 2:05:17 - Epoch: [6][650]\tTime 0.916 (1.314)\tData 0.128 (0.511)\tLoss 8.0064 (8.0065)\tLr: 0.3503\n",
            "INFO - 08/14/24 13:16:19 - 2:06:15 - Epoch: [6][700]\tTime 2.909 (1.302)\tData 2.093 (0.499)\tLoss 8.0065 (8.0065)\tLr: 0.3470\n",
            "INFO - 08/14/24 13:17:17 - 2:07:12 - Epoch: [6][750]\tTime 2.474 (1.292)\tData 1.657 (0.489)\tLoss 8.0065 (8.0065)\tLr: 0.3436\n",
            "INFO - 08/14/24 13:18:21 - 2:08:16 - Epoch: [6][800]\tTime 2.565 (1.291)\tData 1.753 (0.488)\tLoss 8.0064 (8.0065)\tLr: 0.3403\n",
            "INFO - 08/14/24 13:19:24 - 2:09:19 - Epoch: [6][850]\tTime 0.804 (1.290)\tData 0.000 (0.487)\tLoss 8.0064 (8.0065)\tLr: 0.3369\n",
            "INFO - 08/14/24 13:20:35 - 2:10:30 - Epoch: [6][900]\tTime 0.794 (1.297)\tData 0.000 (0.494)\tLoss 8.0065 (8.0065)\tLr: 0.3336\n",
            "INFO - 08/14/24 13:21:26 - 2:11:21 - ============ Starting epoch 7 ... ============\n",
            "INFO - 08/14/24 13:21:28 - 2:11:24 - Epoch: [7][0]\tTime 2.493 (2.493)\tData 1.675 (1.675)\tLoss 8.0065 (8.0065)\tLr: 0.3316\n",
            "INFO - 08/14/24 13:22:17 - 2:12:12 - Epoch: [7][50]\tTime 2.283 (1.000)\tData 1.479 (0.199)\tLoss 8.0065 (8.0065)\tLr: 0.3283\n",
            "INFO - 08/14/24 13:23:20 - 2:13:15 - Epoch: [7][100]\tTime 0.813 (1.130)\tData 0.001 (0.328)\tLoss 8.0064 (8.0065)\tLr: 0.3249\n",
            "INFO - 08/14/24 13:24:36 - 2:14:31 - Epoch: [7][150]\tTime 0.796 (1.259)\tData 0.000 (0.456)\tLoss 8.0065 (8.0065)\tLr: 0.3215\n",
            "INFO - 08/14/24 13:25:45 - 2:15:41 - Epoch: [7][200]\tTime 0.794 (1.291)\tData 0.001 (0.487)\tLoss 8.0065 (8.0065)\tLr: 0.3182\n",
            "INFO - 08/14/24 13:26:54 - 2:16:49 - Epoch: [7][250]\tTime 1.351 (1.308)\tData 0.549 (0.504)\tLoss 8.0065 (8.0065)\tLr: 0.3148\n",
            "INFO - 08/14/24 13:27:54 - 2:17:49 - Epoch: [7][300]\tTime 2.354 (1.290)\tData 1.538 (0.486)\tLoss 8.0065 (8.0065)\tLr: 0.3114\n",
            "INFO - 08/14/24 13:28:44 - 2:18:39 - Epoch: [7][350]\tTime 0.812 (1.249)\tData 0.001 (0.445)\tLoss 8.0064 (8.0065)\tLr: 0.3080\n",
            "INFO - 08/14/24 13:29:55 - 2:19:51 - Epoch: [7][400]\tTime 0.794 (1.270)\tData 0.000 (0.467)\tLoss 8.0064 (8.0065)\tLr: 0.3047\n",
            "INFO - 08/14/24 13:31:06 - 2:21:01 - Epoch: [7][450]\tTime 0.804 (1.286)\tData 0.000 (0.482)\tLoss 8.0064 (8.0065)\tLr: 0.3013\n",
            "INFO - 08/14/24 13:32:14 - 2:22:10 - Epoch: [7][500]\tTime 0.795 (1.295)\tData 0.000 (0.491)\tLoss 8.0065 (8.0065)\tLr: 0.2979\n",
            "INFO - 08/14/24 13:33:24 - 2:23:19 - Epoch: [7][550]\tTime 0.792 (1.304)\tData 0.000 (0.500)\tLoss 8.0064 (8.0065)\tLr: 0.2945\n",
            "INFO - 08/14/24 13:34:19 - 2:24:14 - Epoch: [7][600]\tTime 4.239 (1.287)\tData 3.434 (0.483)\tLoss 8.0064 (8.0065)\tLr: 0.2911\n",
            "INFO - 08/14/24 13:35:20 - 2:25:16 - Epoch: [7][650]\tTime 4.196 (1.282)\tData 3.370 (0.478)\tLoss 8.0065 (8.0065)\tLr: 0.2878\n",
            "INFO - 08/14/24 13:36:27 - 2:26:23 - Epoch: [7][700]\tTime 2.906 (1.286)\tData 2.103 (0.483)\tLoss 8.0065 (8.0065)\tLr: 0.2844\n",
            "INFO - 08/14/24 13:37:27 - 2:27:23 - Epoch: [7][750]\tTime 0.799 (1.280)\tData 0.000 (0.476)\tLoss 8.0065 (8.0065)\tLr: 0.2810\n",
            "INFO - 08/14/24 13:38:39 - 2:28:34 - Epoch: [7][800]\tTime 0.802 (1.289)\tData 0.000 (0.486)\tLoss 8.0064 (8.0065)\tLr: 0.2777\n",
            "INFO - 08/14/24 13:39:48 - 2:29:44 - Epoch: [7][850]\tTime 0.811 (1.295)\tData 0.000 (0.492)\tLoss 8.0064 (8.0065)\tLr: 0.2743\n",
            "INFO - 08/14/24 13:41:00 - 2:30:55 - Epoch: [7][900]\tTime 0.796 (1.303)\tData 0.000 (0.499)\tLoss 8.0065 (8.0065)\tLr: 0.2709\n",
            "INFO - 08/14/24 13:41:22 - 2:31:18 - ============ Starting epoch 8 ... ============\n",
            "INFO - 08/14/24 13:41:24 - 2:31:19 - Epoch: [8][0]\tTime 1.366 (1.366)\tData 0.562 (0.562)\tLoss 8.0065 (8.0065)\tLr: 0.2690\n",
            "INFO - 08/14/24 13:42:32 - 2:32:27 - Epoch: [8][50]\tTime 0.797 (1.358)\tData 0.000 (0.554)\tLoss 8.0064 (8.0065)\tLr: 0.2656\n",
            "INFO - 08/14/24 13:43:46 - 2:33:42 - Epoch: [8][100]\tTime 0.792 (1.425)\tData 0.000 (0.621)\tLoss 8.0064 (8.0065)\tLr: 0.2623\n",
            "INFO - 08/14/24 13:44:59 - 2:34:54 - Epoch: [8][150]\tTime 0.801 (1.432)\tData 0.000 (0.628)\tLoss 8.0065 (8.0065)\tLr: 0.2589\n",
            "INFO - 08/14/24 13:46:05 - 2:36:01 - Epoch: [8][200]\tTime 2.804 (1.408)\tData 1.992 (0.604)\tLoss 8.0065 (8.0065)\tLr: 0.2556\n",
            "INFO - 08/14/24 13:46:58 - 2:36:53 - Epoch: [8][250]\tTime 2.403 (1.336)\tData 1.593 (0.532)\tLoss 8.0065 (8.0065)\tLr: 0.2522\n",
            "INFO - 08/14/24 13:48:02 - 2:37:57 - Epoch: [8][300]\tTime 0.808 (1.328)\tData 0.001 (0.524)\tLoss 8.0065 (8.0065)\tLr: 0.2489\n",
            "INFO - 08/14/24 13:49:11 - 2:39:06 - Epoch: [8][350]\tTime 0.804 (1.334)\tData 0.000 (0.529)\tLoss 8.0064 (8.0065)\tLr: 0.2456\n",
            "INFO - 08/14/24 13:50:22 - 2:40:17 - Epoch: [8][400]\tTime 0.793 (1.345)\tData 0.000 (0.541)\tLoss 8.0064 (8.0065)\tLr: 0.2423\n",
            "INFO - 08/14/24 13:51:33 - 2:41:28 - Epoch: [8][450]\tTime 2.115 (1.353)\tData 1.315 (0.548)\tLoss 8.0064 (8.0065)\tLr: 0.2389\n",
            "INFO - 08/14/24 13:52:21 - 2:42:17 - Epoch: [8][500]\tTime 2.830 (1.315)\tData 2.014 (0.511)\tLoss 8.0065 (8.0065)\tLr: 0.2356\n",
            "INFO - 08/14/24 13:53:23 - 2:43:18 - Epoch: [8][550]\tTime 0.817 (1.308)\tData 0.001 (0.503)\tLoss 8.0064 (8.0065)\tLr: 0.2324\n",
            "INFO - 08/14/24 13:54:33 - 2:44:28 - Epoch: [8][600]\tTime 0.907 (1.315)\tData 0.098 (0.511)\tLoss 8.0064 (8.0065)\tLr: 0.2291\n",
            "INFO - 08/14/24 13:55:41 - 2:45:36 - Epoch: [8][650]\tTime 0.845 (1.319)\tData 0.038 (0.514)\tLoss 8.0065 (8.0065)\tLr: 0.2258\n",
            "INFO - 08/14/24 13:56:50 - 2:46:46 - Epoch: [8][700]\tTime 0.800 (1.324)\tData 0.000 (0.519)\tLoss 8.0064 (8.0065)\tLr: 0.2225\n",
            "INFO - 08/14/24 13:57:58 - 2:47:53 - Epoch: [8][750]\tTime 0.794 (1.326)\tData 0.000 (0.521)\tLoss 8.0064 (8.0065)\tLr: 0.2193\n",
            "INFO - 08/14/24 13:59:04 - 2:48:59 - Epoch: [8][800]\tTime 2.405 (1.325)\tData 1.608 (0.521)\tLoss 8.0064 (8.0065)\tLr: 0.2160\n",
            "INFO - 08/14/24 13:59:56 - 2:49:51 - Epoch: [8][850]\tTime 2.547 (1.309)\tData 1.725 (0.504)\tLoss 8.0064 (8.0065)\tLr: 0.2128\n",
            "INFO - 08/14/24 14:00:55 - 2:50:51 - Epoch: [8][900]\tTime 0.796 (1.302)\tData 0.000 (0.497)\tLoss 8.0064 (8.0065)\tLr: 0.2096\n",
            "INFO - 08/14/24 14:01:46 - 2:51:42 - ============ Starting epoch 9 ... ============\n",
            "INFO - 08/14/24 14:01:48 - 2:51:43 - Epoch: [9][0]\tTime 1.326 (1.326)\tData 0.520 (0.520)\tLoss 8.0064 (8.0064)\tLr: 0.2077\n",
            "INFO - 08/14/24 14:02:49 - 2:52:44 - Epoch: [9][50]\tTime 2.330 (1.222)\tData 1.522 (0.420)\tLoss 8.0064 (8.0064)\tLr: 0.2045\n",
            "INFO - 08/14/24 14:03:42 - 2:53:37 - Epoch: [9][100]\tTime 1.584 (1.147)\tData 0.777 (0.345)\tLoss 8.0064 (8.0064)\tLr: 0.2013\n",
            "INFO - 08/14/24 14:04:45 - 2:54:41 - Epoch: [9][150]\tTime 0.809 (1.186)\tData 0.000 (0.383)\tLoss 8.0065 (8.0064)\tLr: 0.1981\n",
            "INFO - 08/14/24 14:05:53 - 2:55:49 - Epoch: [9][200]\tTime 0.800 (1.229)\tData 0.000 (0.425)\tLoss 8.0065 (8.0065)\tLr: 0.1949\n",
            "INFO - 08/14/24 14:07:05 - 2:57:01 - Epoch: [9][250]\tTime 0.791 (1.271)\tData 0.000 (0.467)\tLoss 8.0065 (8.0065)\tLr: 0.1918\n",
            "INFO - 08/14/24 14:08:02 - 2:57:57 - Epoch: [9][300]\tTime 2.276 (1.249)\tData 1.469 (0.445)\tLoss 8.0064 (8.0065)\tLr: 0.1886\n",
            "INFO - 08/14/24 14:08:53 - 2:58:49 - Epoch: [9][350]\tTime 0.809 (1.217)\tData 0.001 (0.413)\tLoss 8.0064 (8.0065)\tLr: 0.1855\n",
            "INFO - 08/14/24 14:10:03 - 2:59:59 - Epoch: [9][400]\tTime 0.809 (1.240)\tData 0.000 (0.436)\tLoss 8.0064 (8.0065)\tLr: 0.1824\n",
            "INFO - 08/14/24 14:11:10 - 3:01:05 - Epoch: [9][450]\tTime 0.801 (1.250)\tData 0.000 (0.446)\tLoss 8.0064 (8.0064)\tLr: 0.1793\n",
            "INFO - 08/14/24 14:12:24 - 3:02:20 - Epoch: [9][500]\tTime 0.808 (1.274)\tData 0.000 (0.470)\tLoss 8.0065 (8.0064)\tLr: 0.1762\n",
            "INFO - 08/14/24 14:13:13 - 3:03:08 - Epoch: [9][550]\tTime 2.774 (1.247)\tData 1.959 (0.443)\tLoss 8.0064 (8.0064)\tLr: 0.1731\n",
            "INFO - 08/14/24 14:14:18 - 3:04:14 - Epoch: [9][600]\tTime 1.195 (1.251)\tData 0.368 (0.447)\tLoss 8.0064 (8.0064)\tLr: 0.1701\n",
            "INFO - 08/14/24 14:15:29 - 3:05:24 - Epoch: [9][650]\tTime 0.976 (1.264)\tData 0.184 (0.460)\tLoss 8.0064 (8.0064)\tLr: 0.1671\n",
            "INFO - 08/14/24 14:16:40 - 3:06:35 - Epoch: [9][700]\tTime 0.789 (1.275)\tData 0.000 (0.472)\tLoss 8.0064 (8.0064)\tLr: 0.1640\n",
            "INFO - 08/14/24 14:17:52 - 3:07:47 - Epoch: [9][750]\tTime 0.797 (1.286)\tData 0.000 (0.483)\tLoss 8.0065 (8.0064)\tLr: 0.1610\n",
            "INFO - 08/14/24 14:19:02 - 3:08:58 - Epoch: [9][800]\tTime 1.016 (1.294)\tData 0.231 (0.491)\tLoss 8.0064 (8.0064)\tLr: 0.1581\n",
            "INFO - 08/14/24 14:19:58 - 3:09:53 - Epoch: [9][850]\tTime 2.542 (1.283)\tData 1.742 (0.480)\tLoss 8.0064 (8.0064)\tLr: 0.1551\n",
            "INFO - 08/14/24 14:20:51 - 3:10:46 - Epoch: [9][900]\tTime 1.861 (1.270)\tData 1.045 (0.468)\tLoss 8.0064 (8.0064)\tLr: 0.1522\n",
            "INFO - 08/14/24 14:21:48 - 3:11:43 - ============ Starting epoch 10 ... ============\n",
            "INFO - 08/14/24 14:21:49 - 3:11:45 - Epoch: [10][0]\tTime 1.275 (1.275)\tData 0.474 (0.474)\tLoss 8.0064 (8.0064)\tLr: 0.1505\n",
            "INFO - 08/14/24 14:22:51 - 3:12:46 - Epoch: [10][50]\tTime 2.413 (1.231)\tData 1.599 (0.427)\tLoss 8.0064 (8.0064)\tLr: 0.1475\n",
            "INFO - 08/14/24 14:24:00 - 3:13:56 - Epoch: [10][100]\tTime 1.487 (1.311)\tData 0.674 (0.507)\tLoss 8.0064 (8.0064)\tLr: 0.1446\n",
            "INFO - 08/14/24 14:24:52 - 3:14:47 - Epoch: [10][150]\tTime 2.741 (1.216)\tData 1.922 (0.412)\tLoss 8.0065 (8.0064)\tLr: 0.1418\n",
            "INFO - 08/14/24 14:25:58 - 3:15:54 - Epoch: [10][200]\tTime 0.793 (1.246)\tData 0.001 (0.442)\tLoss 8.0065 (8.0065)\tLr: 0.1389\n",
            "INFO - 08/14/24 14:27:08 - 3:17:03 - Epoch: [10][250]\tTime 0.790 (1.273)\tData 0.000 (0.470)\tLoss 8.0064 (8.0065)\tLr: 0.1361\n",
            "INFO - 08/14/24 14:28:21 - 3:18:16 - Epoch: [10][300]\tTime 0.796 (1.306)\tData 0.000 (0.502)\tLoss 8.0065 (8.0064)\tLr: 0.1333\n",
            "INFO - 08/14/24 14:29:28 - 3:19:24 - Epoch: [10][350]\tTime 0.786 (1.312)\tData 0.000 (0.508)\tLoss 8.0064 (8.0064)\tLr: 0.1305\n",
            "INFO - 08/14/24 14:30:36 - 3:20:32 - Epoch: [10][400]\tTime 2.434 (1.317)\tData 1.631 (0.514)\tLoss 8.0064 (8.0064)\tLr: 0.1277\n",
            "INFO - 08/14/24 14:31:26 - 3:21:21 - Epoch: [10][450]\tTime 2.464 (1.281)\tData 1.644 (0.478)\tLoss 8.0064 (8.0064)\tLr: 0.1249\n",
            "INFO - 08/14/24 14:32:33 - 3:22:28 - Epoch: [10][500]\tTime 0.799 (1.288)\tData 0.001 (0.484)\tLoss 8.0065 (8.0064)\tLr: 0.1222\n",
            "INFO - 08/14/24 14:33:43 - 3:23:39 - Epoch: [10][550]\tTime 0.820 (1.298)\tData 0.001 (0.494)\tLoss 8.0064 (8.0064)\tLr: 0.1195\n",
            "INFO - 08/14/24 14:34:57 - 3:24:53 - Epoch: [10][600]\tTime 0.827 (1.313)\tData 0.038 (0.509)\tLoss 8.0064 (8.0064)\tLr: 0.1168\n",
            "INFO - 08/14/24 14:36:10 - 3:26:05 - Epoch: [10][650]\tTime 0.931 (1.324)\tData 0.137 (0.521)\tLoss 8.0064 (8.0064)\tLr: 0.1142\n",
            "INFO - 08/14/24 14:37:12 - 3:27:07 - Epoch: [10][700]\tTime 2.902 (1.318)\tData 2.091 (0.515)\tLoss 8.0064 (8.0064)\tLr: 0.1115\n",
            "INFO - 08/14/24 14:38:11 - 3:28:06 - Epoch: [10][750]\tTime 2.575 (1.308)\tData 1.762 (0.505)\tLoss 8.0064 (8.0064)\tLr: 0.1089\n",
            "INFO - 08/14/24 14:39:12 - 3:29:07 - Epoch: [10][800]\tTime 0.811 (1.303)\tData 0.001 (0.499)\tLoss 8.0064 (8.0064)\tLr: 0.1063\n",
            "INFO - 08/14/24 14:40:27 - 3:30:22 - Epoch: [10][850]\tTime 0.807 (1.315)\tData 0.000 (0.511)\tLoss 8.0064 (8.0064)\tLr: 0.1038\n",
            "INFO - 08/14/24 14:41:39 - 3:31:34 - Epoch: [10][900]\tTime 0.791 (1.322)\tData 0.000 (0.517)\tLoss 8.0064 (8.0064)\tLr: 0.1012\n",
            "INFO - 08/14/24 14:42:03 - 3:31:59 - ============ Starting epoch 11 ... ============\n",
            "INFO - 08/14/24 14:42:06 - 3:32:01 - Epoch: [11][0]\tTime 2.452 (2.452)\tData 1.602 (1.602)\tLoss 8.0064 (8.0064)\tLr: 0.0998\n",
            "INFO - 08/14/24 14:43:15 - 3:33:10 - Epoch: [11][50]\tTime 0.786 (1.398)\tData 0.000 (0.601)\tLoss 8.0064 (8.0064)\tLr: 0.0973\n",
            "INFO - 08/14/24 14:44:28 - 3:34:24 - Epoch: [11][100]\tTime 0.788 (1.436)\tData 0.000 (0.639)\tLoss 8.0064 (8.0064)\tLr: 0.0948\n",
            "INFO - 08/14/24 14:45:34 - 3:35:29 - Epoch: [11][150]\tTime 0.805 (1.396)\tData 0.000 (0.599)\tLoss 8.0065 (8.0064)\tLr: 0.0923\n",
            "INFO - 08/14/24 14:46:40 - 3:36:36 - Epoch: [11][200]\tTime 0.783 (1.378)\tData 0.000 (0.582)\tLoss 8.0065 (8.0065)\tLr: 0.0899\n",
            "INFO - 08/14/24 14:47:39 - 3:37:35 - Epoch: [11][250]\tTime 2.568 (1.339)\tData 1.771 (0.543)\tLoss 8.0064 (8.0065)\tLr: 0.0875\n",
            "INFO - 08/14/24 14:48:31 - 3:38:27 - Epoch: [11][300]\tTime 0.807 (1.290)\tData 0.001 (0.493)\tLoss 8.0064 (8.0064)\tLr: 0.0852\n",
            "INFO - 08/14/24 14:49:45 - 3:39:40 - Epoch: [11][350]\tTime 0.790 (1.314)\tData 0.000 (0.518)\tLoss 8.0064 (8.0064)\tLr: 0.0828\n",
            "INFO - 08/14/24 14:50:54 - 3:40:49 - Epoch: [11][400]\tTime 0.788 (1.324)\tData 0.000 (0.527)\tLoss 8.0064 (8.0064)\tLr: 0.0805\n",
            "INFO - 08/14/24 14:51:59 - 3:41:55 - Epoch: [11][450]\tTime 2.268 (1.322)\tData 1.460 (0.525)\tLoss 8.0064 (8.0064)\tLr: 0.0782\n",
            "INFO - 08/14/24 14:52:52 - 3:42:47 - Epoch: [11][500]\tTime 2.848 (1.295)\tData 2.047 (0.498)\tLoss 8.0064 (8.0064)\tLr: 0.0760\n",
            "INFO - 08/14/24 14:53:54 - 3:43:50 - Epoch: [11][550]\tTime 0.788 (1.290)\tData 0.000 (0.494)\tLoss 8.0064 (8.0064)\tLr: 0.0738\n",
            "INFO - 08/14/24 14:55:05 - 3:45:00 - Epoch: [11][600]\tTime 0.880 (1.301)\tData 0.090 (0.504)\tLoss 8.0064 (8.0064)\tLr: 0.0716\n",
            "INFO - 08/14/24 14:56:17 - 3:46:12 - Epoch: [11][650]\tTime 1.002 (1.311)\tData 0.210 (0.514)\tLoss 8.0065 (8.0064)\tLr: 0.0694\n",
            "INFO - 08/14/24 14:57:27 - 3:47:22 - Epoch: [11][700]\tTime 0.821 (1.317)\tData 0.000 (0.520)\tLoss 8.0064 (8.0064)\tLr: 0.0673\n",
            "INFO - 08/14/24 14:58:16 - 3:48:11 - Epoch: [11][750]\tTime 2.608 (1.295)\tData 1.794 (0.497)\tLoss 8.0065 (8.0064)\tLr: 0.0651\n",
            "INFO - 08/14/24 14:59:12 - 3:49:07 - Epoch: [11][800]\tTime 0.791 (1.284)\tData 0.000 (0.487)\tLoss 8.0064 (8.0064)\tLr: 0.0631\n",
            "INFO - 08/14/24 15:00:21 - 3:50:16 - Epoch: [11][850]\tTime 0.808 (1.289)\tData 0.000 (0.492)\tLoss 8.0064 (8.0064)\tLr: 0.0610\n",
            "INFO - 08/14/24 15:01:30 - 3:51:25 - Epoch: [11][900]\tTime 0.791 (1.295)\tData 0.000 (0.497)\tLoss 8.0064 (8.0064)\tLr: 0.0590\n",
            "INFO - 08/14/24 15:02:03 - 3:51:59 - ============ Starting epoch 12 ... ============\n",
            "INFO - 08/14/24 15:02:07 - 3:52:02 - Epoch: [12][0]\tTime 3.185 (3.185)\tData 2.350 (2.350)\tLoss 8.0064 (8.0064)\tLr: 0.0578\n",
            "INFO - 08/14/24 15:02:58 - 3:52:54 - Epoch: [12][50]\tTime 0.791 (1.076)\tData 0.000 (0.284)\tLoss 8.0064 (8.0064)\tLr: 0.0559\n",
            "INFO - 08/14/24 15:04:06 - 3:54:01 - Epoch: [12][100]\tTime 0.798 (1.212)\tData 0.000 (0.415)\tLoss 8.0064 (8.0064)\tLr: 0.0539\n",
            "INFO - 08/14/24 15:05:13 - 3:55:08 - Epoch: [12][150]\tTime 0.795 (1.256)\tData 0.000 (0.459)\tLoss 8.0065 (8.0064)\tLr: 0.0520\n",
            "INFO - 08/14/24 15:06:16 - 3:56:11 - Epoch: [12][200]\tTime 0.790 (1.257)\tData 0.000 (0.460)\tLoss 8.0065 (8.0065)\tLr: 0.0501\n",
            "INFO - 08/14/24 15:07:12 - 3:57:07 - Epoch: [12][250]\tTime 2.484 (1.230)\tData 1.678 (0.433)\tLoss 8.0064 (8.0065)\tLr: 0.0483\n",
            "INFO - 08/14/24 15:07:59 - 3:57:54 - Epoch: [12][300]\tTime 0.817 (1.181)\tData 0.001 (0.385)\tLoss 8.0065 (8.0064)\tLr: 0.0465\n",
            "INFO - 08/14/24 15:09:08 - 3:59:03 - Epoch: [12][350]\tTime 0.808 (1.208)\tData 0.000 (0.412)\tLoss 8.0064 (8.0064)\tLr: 0.0447\n",
            "INFO - 08/14/24 15:10:14 - 4:00:09 - Epoch: [12][400]\tTime 0.792 (1.223)\tData 0.000 (0.426)\tLoss 8.0064 (8.0064)\tLr: 0.0430\n",
            "INFO - 08/14/24 15:11:22 - 4:01:17 - Epoch: [12][450]\tTime 0.833 (1.238)\tData 0.000 (0.441)\tLoss 8.0064 (8.0064)\tLr: 0.0412\n",
            "INFO - 08/14/24 15:12:18 - 4:02:14 - Epoch: [12][500]\tTime 3.016 (1.227)\tData 2.159 (0.426)\tLoss 8.0065 (8.0064)\tLr: 0.0396\n",
            "INFO - 08/14/24 15:13:15 - 4:03:10 - Epoch: [12][550]\tTime 0.793 (1.219)\tData 0.000 (0.418)\tLoss 8.0064 (8.0064)\tLr: 0.0379\n",
            "INFO - 08/14/24 15:14:26 - 4:04:21 - Epoch: [12][600]\tTime 0.908 (1.235)\tData 0.121 (0.435)\tLoss 8.0064 (8.0064)\tLr: 0.0363\n",
            "INFO - 08/14/24 15:15:33 - 4:05:29 - Epoch: [12][650]\tTime 0.904 (1.244)\tData 0.110 (0.444)\tLoss 8.0064 (8.0064)\tLr: 0.0347\n",
            "INFO - 08/14/24 15:16:43 - 4:06:38 - Epoch: [12][700]\tTime 0.785 (1.254)\tData 0.000 (0.455)\tLoss 8.0064 (8.0064)\tLr: 0.0332\n",
            "INFO - 08/14/24 15:17:36 - 4:07:31 - Epoch: [12][750]\tTime 2.465 (1.242)\tData 1.648 (0.442)\tLoss 8.0064 (8.0064)\tLr: 0.0317\n",
            "INFO - 08/14/24 15:18:33 - 4:08:28 - Epoch: [12][800]\tTime 0.800 (1.236)\tData 0.000 (0.436)\tLoss 8.0064 (8.0064)\tLr: 0.0302\n",
            "INFO - 08/14/24 15:19:44 - 4:09:39 - Epoch: [12][850]\tTime 0.797 (1.246)\tData 0.000 (0.447)\tLoss 8.0064 (8.0064)\tLr: 0.0287\n",
            "INFO - 08/14/24 15:20:54 - 4:10:49 - Epoch: [12][900]\tTime 0.789 (1.255)\tData 0.000 (0.456)\tLoss 8.0064 (8.0064)\tLr: 0.0273\n",
            "INFO - 08/14/24 15:21:24 - 4:11:19 - ============ Starting epoch 13 ... ============\n",
            "INFO - 08/14/24 15:21:27 - 4:11:22 - Epoch: [13][0]\tTime 3.098 (3.098)\tData 2.267 (2.267)\tLoss 8.0065 (8.0065)\tLr: 0.0265\n",
            "INFO - 08/14/24 15:22:30 - 4:12:25 - Epoch: [13][50]\tTime 0.804 (1.300)\tData 0.000 (0.489)\tLoss 8.0064 (8.0064)\tLr: 0.0252\n",
            "INFO - 08/14/24 15:23:47 - 4:13:42 - Epoch: [13][100]\tTime 0.790 (1.416)\tData 0.000 (0.611)\tLoss 8.0064 (8.0064)\tLr: 0.0238\n",
            "INFO - 08/14/24 15:24:57 - 4:14:52 - Epoch: [13][150]\tTime 0.795 (1.412)\tData 0.000 (0.609)\tLoss 8.0066 (8.0064)\tLr: 0.0225\n",
            "INFO - 08/14/24 15:26:07 - 4:16:03 - Epoch: [13][200]\tTime 0.782 (1.410)\tData 0.000 (0.608)\tLoss 8.0065 (8.0065)\tLr: 0.0213\n",
            "INFO - 08/14/24 15:27:11 - 4:17:07 - Epoch: [13][250]\tTime 2.428 (1.385)\tData 1.619 (0.584)\tLoss 8.0065 (8.0064)\tLr: 0.0201\n",
            "INFO - 08/14/24 15:28:03 - 4:17:58 - Epoch: [13][300]\tTime 2.337 (1.325)\tData 1.525 (0.525)\tLoss 8.0064 (8.0064)\tLr: 0.0189\n",
            "INFO - 08/14/24 15:29:12 - 4:19:08 - Epoch: [13][350]\tTime 0.789 (1.334)\tData 0.000 (0.534)\tLoss 8.0064 (8.0064)\tLr: 0.0178\n",
            "INFO - 08/14/24 15:30:26 - 4:20:21 - Epoch: [13][400]\tTime 0.786 (1.352)\tData 0.000 (0.552)\tLoss 8.0064 (8.0064)\tLr: 0.0166\n",
            "INFO - 08/14/24 15:31:35 - 4:21:30 - Epoch: [13][450]\tTime 0.807 (1.355)\tData 0.000 (0.556)\tLoss 8.0064 (8.0064)\tLr: 0.0156\n",
            "INFO - 08/14/24 15:32:42 - 4:22:37 - Epoch: [13][500]\tTime 1.800 (1.353)\tData 1.012 (0.554)\tLoss 8.0065 (8.0064)\tLr: 0.0145\n",
            "INFO - 08/14/24 15:33:34 - 4:23:29 - Epoch: [13][550]\tTime 2.770 (1.325)\tData 1.963 (0.526)\tLoss 8.0064 (8.0064)\tLr: 0.0135\n",
            "INFO - 08/14/24 15:34:38 - 4:24:33 - Epoch: [13][600]\tTime 4.026 (1.321)\tData 3.203 (0.522)\tLoss 8.0064 (8.0064)\tLr: 0.0126\n",
            "INFO - 08/14/24 15:35:46 - 4:25:41 - Epoch: [13][650]\tTime 4.105 (1.324)\tData 3.302 (0.526)\tLoss 8.0065 (8.0064)\tLr: 0.0116\n",
            "INFO - 08/14/24 15:36:47 - 4:26:42 - Epoch: [13][700]\tTime 0.794 (1.316)\tData 0.000 (0.518)\tLoss 8.0064 (8.0064)\tLr: 0.0108\n",
            "INFO - 08/14/24 15:37:57 - 4:27:52 - Epoch: [13][750]\tTime 0.791 (1.322)\tData 0.001 (0.524)\tLoss 8.0065 (8.0064)\tLr: 0.0099\n",
            "INFO - 08/14/24 15:39:07 - 4:29:02 - Epoch: [13][800]\tTime 0.798 (1.327)\tData 0.000 (0.528)\tLoss 8.0064 (8.0064)\tLr: 0.0091\n",
            "INFO - 08/14/24 15:40:18 - 4:30:13 - Epoch: [13][850]\tTime 0.783 (1.333)\tData 0.000 (0.534)\tLoss 8.0065 (8.0064)\tLr: 0.0083\n",
            "INFO - 08/14/24 15:41:28 - 4:31:24 - Epoch: [13][900]\tTime 0.787 (1.337)\tData 0.000 (0.539)\tLoss 8.0064 (8.0064)\tLr: 0.0076\n",
            "INFO - 08/14/24 15:41:51 - 4:31:46 - ============ Starting epoch 14 ... ============\n",
            "INFO - 08/14/24 15:41:52 - 4:31:48 - Epoch: [14][0]\tTime 1.345 (1.345)\tData 0.536 (0.536)\tLoss 8.0064 (8.0064)\tLr: 0.0071\n",
            "INFO - 08/14/24 15:43:03 - 4:32:58 - Epoch: [14][50]\tTime 0.787 (1.402)\tData 0.000 (0.605)\tLoss 8.0065 (8.0064)\tLr: 0.0065\n",
            "INFO - 08/14/24 15:44:20 - 4:34:15 - Epoch: [14][100]\tTime 0.781 (1.471)\tData 0.001 (0.674)\tLoss 8.0064 (8.0064)\tLr: 0.0058\n",
            "INFO - 08/14/24 15:45:19 - 4:35:15 - Epoch: [14][150]\tTime 2.877 (1.380)\tData 2.078 (0.582)\tLoss 8.0066 (8.0064)\tLr: 0.0052\n",
            "INFO - 08/14/24 15:46:12 - 4:36:08 - Epoch: [14][200]\tTime 0.795 (1.300)\tData 0.000 (0.503)\tLoss 8.0064 (8.0064)\tLr: 0.0046\n",
            "INFO - 08/14/24 15:47:23 - 4:37:18 - Epoch: [14][250]\tTime 0.785 (1.322)\tData 0.000 (0.526)\tLoss 8.0064 (8.0064)\tLr: 0.0041\n",
            "INFO - 08/14/24 15:48:32 - 4:38:28 - Epoch: [14][300]\tTime 0.787 (1.333)\tData 0.000 (0.536)\tLoss 8.0064 (8.0064)\tLr: 0.0036\n",
            "INFO - 08/14/24 15:49:41 - 4:39:37 - Epoch: [14][350]\tTime 0.784 (1.340)\tData 0.000 (0.542)\tLoss 8.0064 (8.0064)\tLr: 0.0031\n",
            "INFO - 08/14/24 15:50:43 - 4:40:39 - Epoch: [14][400]\tTime 2.274 (1.328)\tData 1.468 (0.531)\tLoss 8.0064 (8.0064)\tLr: 0.0027\n",
            "INFO - 08/14/24 15:51:30 - 4:41:26 - Epoch: [14][450]\tTime 0.813 (1.284)\tData 0.001 (0.488)\tLoss 8.0064 (8.0064)\tLr: 0.0023\n",
            "INFO - 08/14/24 15:52:40 - 4:42:36 - Epoch: [14][500]\tTime 0.793 (1.296)\tData 0.000 (0.499)\tLoss 8.0064 (8.0064)\tLr: 0.0020\n",
            "INFO - 08/14/24 15:53:50 - 4:43:45 - Epoch: [14][550]\tTime 0.789 (1.304)\tData 0.000 (0.507)\tLoss 8.0064 (8.0064)\tLr: 0.0017\n",
            "INFO - 08/14/24 15:54:59 - 4:44:54 - Epoch: [14][600]\tTime 0.880 (1.311)\tData 0.098 (0.514)\tLoss 8.0064 (8.0064)\tLr: 0.0014\n",
            "INFO - 08/14/24 15:56:07 - 4:46:02 - Epoch: [14][650]\tTime 3.431 (1.314)\tData 2.629 (0.518)\tLoss 8.0064 (8.0064)\tLr: 0.0012\n",
            "INFO - 08/14/24 15:56:51 - 4:46:47 - Epoch: [14][700]\tTime 2.245 (1.284)\tData 1.432 (0.488)\tLoss 8.0064 (8.0064)\tLr: 0.0010\n",
            "INFO - 08/14/24 15:58:00 - 4:47:55 - Epoch: [14][750]\tTime 0.835 (1.290)\tData 0.000 (0.493)\tLoss 8.0065 (8.0064)\tLr: 0.0008\n",
            "INFO - 08/14/24 15:59:14 - 4:49:09 - Epoch: [14][800]\tTime 0.789 (1.302)\tData 0.001 (0.505)\tLoss 8.0064 (8.0064)\tLr: 0.0007\n",
            "INFO - 08/14/24 16:00:23 - 4:50:19 - Epoch: [14][850]\tTime 2.470 (1.307)\tData 1.659 (0.509)\tLoss 8.0064 (8.0064)\tLr: 0.0006\n",
            "INFO - 08/14/24 16:01:11 - 4:51:07 - Epoch: [14][900]\tTime 1.610 (1.288)\tData 0.857 (0.491)\tLoss 8.0064 (8.0064)\tLr: 0.0006\n"
          ]
        }
      ],
      "source": [
        "    %cd /home/jetshu/Documents/PLAEX/code/SwAV/swav_single_gpu/\n",
        "    !python main_swav_no_apex.py \\\n",
        "    --data_path $TRAIN_DATASET_PATH \\\n",
        "    --epochs 15 \\\n",
        "    --base_lr 0.6 \\\n",
        "    --final_lr 0.0006 \\\n",
        "    --warmup_epochs 0 \\\n",
        "    --batch_size 16 \\\n",
        "    --workers 1 \\\n",
        "    --size_crops 224 96 \\\n",
        "    --nmb_crops 2 6 \\\n",
        "    --min_scale_crops 0.14 0.05 \\\n",
        "    --max_scale_crops 1. 0.14 \\\n",
        "    --use_fp16 true \\\n",
        "    --freeze_prototypes_niters 5005 \\\n",
        "    --queue_length 3840 \\\n",
        "    --epoch_queue_starts 15 \\\n",
        "    --crops_for_assign 0 1 \\\n",
        "    --temperature 0.1 \\\n",
        "    --epsilon 0.05 \\\n",
        "    --sinkhorn_iterations 3 \\\n",
        "    --feat_dim 128 \\\n",
        "    --nmb_prototypes 3000 \\\n",
        "    --wd 0.000001 \\\n",
        "    --arch resnet50 \\\n",
        "    --dump_path $EXPERIMENT_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: LOG=log\n",
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 9636), started 0:01:46 ago. (Use '!kill 9636' to kill it.)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-7e3aa56f19cd376f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-7e3aa56f19cd376f\");\n",
              "          const url = new URL(\"http://localhost\");\n",
              "          const port = 6006;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%env LOG=log\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir $EXPERIMENT_PATH/$LOG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9KyHG3_IeMV"
      },
      "source": [
        "Copy final modifications into our Google Drive files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcmX2jUCdVJt"
      },
      "outputs": [],
      "source": [
        "#!cp -f /content/swav/main_swav_no_apex.py /content/drive/MyDrive/PLAEX/Selfsupervised_models/swav/code/\n",
        "#!cp -f /content/swav/src/utils.py /content/drive/MyDrive/PLAEX/Selfsupervised_models/swav/code/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8wVkXzEG_Cl"
      },
      "source": [
        "### 2.2. Supervised learning of Linear Classification on top of SwAV model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGJx9u7OHEV0",
        "outputId": "862bf95f-fb1b-4026-fd3b-768417f8c765"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/swav\n",
            "INFO - 08/12/24 07:24:05 - 0:00:00 - ============ Initialized logger ============\n",
            "INFO - 08/12/24 07:24:05 - 0:00:00 - arch: resnet50\n",
            "                                     batch_size: 32\n",
            "                                     data_path: /content/drive/MyDrive/PLAEX/Dataset\n",
            "                                     decay_epochs: [60, 80]\n",
            "                                     dump_checkpoints: ./checkpoints\n",
            "                                     dump_path: .\n",
            "                                     epochs: 100\n",
            "                                     final_lr: 0\n",
            "                                     gamma: 0.1\n",
            "                                     global_pooling: True\n",
            "                                     lr: 0.3\n",
            "                                     nesterov: False\n",
            "                                     pretrained: /content/drive/MyDrive/PLAEX/Selfsupervised_models/swav/experiments/swav_400ep_bs256_pretrain/swav_400ep_bs256_pretrain.pth.tar\n",
            "                                     scheduler_type: cosine\n",
            "                                     seed: 31\n",
            "                                     use_bn: False\n",
            "                                     wd: 1e-06\n",
            "                                     workers: 10\n",
            "INFO - 08/12/24 07:24:05 - 0:00:00 - The experiment will be stored in .\n",
            "                                     \n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "INFO - 08/12/24 07:24:05 - 0:00:00 - Building data done\n",
            "INFO - 08/12/24 07:24:06 - 0:00:01 - Load pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['projection_head.0.weight', 'projection_head.0.bias', 'projection_head.1.weight', 'projection_head.1.bias', 'projection_head.1.running_mean', 'projection_head.1.running_var', 'projection_head.1.num_batches_tracked', 'projection_head.3.weight', 'projection_head.3.bias', 'prototypes.weight'])\n",
            "INFO - 08/12/24 07:24:06 - 0:00:01 - No checkpoint has found at ./checkpoint.pth.tar\n",
            "INFO - 08/12/24 07:24:06 - 0:00:01 - ============ Starting epoch 0 ... ============\n",
            "INFO - 08/12/24 07:24:08 - 0:00:03 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:08 - 0:00:03 - Epoch[0] - Iter: [0/2]\tTime 2.130 (2.130)\tData 0.632 (0.632)\tLoss 6.9687 (6.9687)\tPrec 0.000 (0.000)\tLR 0.3\n",
            "INFO - 08/12/24 07:24:08 - 0:00:03 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:09 - 0:00:04 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:09 - 0:00:04 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:09 - 0:00:04 - Test:\tTime 0.383\tLoss 1.4267\tAcc@1 35.294\tBest Acc@1 so far 35.3\n",
            "INFO - 08/12/24 07:24:09 - 0:00:04 - ============ Starting epoch 1 ... ============\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "INFO - 08/12/24 07:24:10 - 0:00:05 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:10 - 0:00:05 - Epoch[1] - Iter: [0/2]\tTime 0.727 (0.727)\tData 0.649 (0.649)\tLoss 1.5049 (1.5049)\tPrec 31.250 (31.250)\tLR 0.2999259840548597\n",
            "INFO - 08/12/24 07:24:10 - 0:00:05 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:11 - 0:00:06 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:11 - 0:00:06 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:12 - 0:00:06 - Test:\tTime 0.572\tLoss 0.8434\tAcc@1 73.529\tBest Acc@1 so far 73.5\n",
            "INFO - 08/12/24 07:24:12 - 0:00:06 - ============ Starting epoch 2 ... ============\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "INFO - 08/12/24 07:24:13 - 0:00:07 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:13 - 0:00:07 - Epoch[2] - Iter: [0/2]\tTime 0.973 (0.973)\tData 0.888 (0.888)\tLoss 0.8165 (0.8165)\tPrec 75.000 (75.000)\tLR 0.29970400926424073\n",
            "INFO - 08/12/24 07:24:13 - 0:00:07 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:14 - 0:00:08 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:14 - 0:00:09 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:14 - 0:00:09 - Test:\tTime 0.560\tLoss 0.5987\tAcc@1 76.471\tBest Acc@1 so far 76.5\n",
            "INFO - 08/12/24 07:24:14 - 0:00:09 - ============ Starting epoch 3 ... ============\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "INFO - 08/12/24 07:24:15 - 0:00:09 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:15 - 0:00:10 - Epoch[3] - Iter: [0/2]\tTime 0.819 (0.819)\tData 0.738 (0.738)\tLoss 0.5047 (0.5047)\tPrec 81.250 (81.250)\tLR 0.299334294690462\n",
            "INFO - 08/12/24 07:24:15 - 0:00:10 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:16 - 0:00:10 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:16 - 0:00:10 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:16 - 0:00:11 - Test:\tTime 0.389\tLoss 0.8926\tAcc@1 61.765\tBest Acc@1 so far 76.5\n",
            "INFO - 08/12/24 07:24:16 - 0:00:11 - ============ Starting epoch 4 ... ============\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "INFO - 08/12/24 07:24:16 - 0:00:11 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:16 - 0:00:11 - Epoch[4] - Iter: [0/2]\tTime 0.643 (0.643)\tData 0.563 (0.563)\tLoss 0.8684 (0.8684)\tPrec 56.250 (56.250)\tLR 0.2988172051971717\n",
            "INFO - 08/12/24 07:24:16 - 0:00:11 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:17 - 0:00:12 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:17 - 0:00:12 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:17 - 0:00:12 - Test:\tTime 0.393\tLoss 0.9938\tAcc@1 73.529\tBest Acc@1 so far 76.5\n",
            "INFO - 08/12/24 07:24:17 - 0:00:12 - ============ Starting epoch 5 ... ============\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "INFO - 08/12/24 07:24:18 - 0:00:13 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:18 - 0:00:13 - Epoch[5] - Iter: [0/2]\tTime 0.649 (0.649)\tData 0.569 (0.569)\tLoss 1.0060 (1.0060)\tPrec 71.875 (71.875)\tLR 0.29815325108927065\n",
            "INFO - 08/12/24 07:24:18 - 0:00:13 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:19 - 0:00:14 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:19 - 0:00:14 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:19 - 0:00:14 - Test:\tTime 0.405\tLoss 0.8110\tAcc@1 76.471\tBest Acc@1 so far 76.5\n",
            "INFO - 08/12/24 07:24:19 - 0:00:14 - ============ Starting epoch 6 ... ============\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "INFO - 08/12/24 07:24:20 - 0:00:14 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:20 - 0:00:14 - Epoch[6] - Iter: [0/2]\tTime 0.662 (0.662)\tData 0.581 (0.581)\tLoss 0.7547 (0.7547)\tPrec 75.000 (75.000)\tLR 0.29734308760930334\n",
            "INFO - 08/12/24 07:24:20 - 0:00:15 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:21 - 0:00:15 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:21 - 0:00:15 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:21 - 0:00:16 - Test:\tTime 0.447\tLoss 0.4674\tAcc@1 82.353\tBest Acc@1 so far 82.4\n",
            "INFO - 08/12/24 07:24:21 - 0:00:16 - ============ Starting epoch 7 ... ============\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "INFO - 08/12/24 07:24:21 - 0:00:16 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:22 - 0:00:16 - Epoch[7] - Iter: [0/2]\tTime 0.690 (0.690)\tData 0.579 (0.579)\tLoss 0.3910 (0.3910)\tPrec 78.125 (78.125)\tLR 0.2963875142908121\n",
            "INFO - 08/12/24 07:24:22 - 0:00:16 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:22 - 0:00:17 - Correct size: 'torch.Size([5, 32])'\n",
            "INFO - 08/12/24 07:24:23 - 0:00:17 - Correct size: 'torch.Size([5, 2])'\n",
            "INFO - 08/12/24 07:24:23 - 0:00:17 - Test:\tTime 0.408\tLoss 0.2881\tAcc@1 91.176\tBest Acc@1 so far 91.2\n",
            "INFO - 08/12/24 07:24:23 - 0:00:17 - ============ Starting epoch 8 ... ============\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1329, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1285, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1133, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.10/queue.py\", line 180, in get\n",
            "    self.not_empty.wait(remaining)\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 324, in wait\n",
            "    gotit = waiter.acquire(True, timeout)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/swav/eval_linear_no_distribution.py\", line 362, in <module>\n",
            "    main()\n",
            "  File \"/content/swav/eval_linear_no_distribution.py\", line 180, in main\n",
            "    scores = train(model, linear_classifier, optimizer, train_loader, epoch)\n",
            "  File \"/content/swav/eval_linear_no_distribution.py\", line 257, in train\n",
            "    for iter_epoch, (inp, target) in enumerate(loader):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 627, in __next__\n",
            "    with torch.autograd.profiler.record_function(self._profile_name):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/profiler.py\", line 620, in __exit__\n",
            "    if not torch.jit.is_scripting():\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_jit_internal.py\", line 1120, in is_scripting\n",
            "    def is_scripting() -> bool:\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "checkpoint = \"swav_400ep_bs256_pretrain.pth.tar\"\n",
        "os.environ['CHECKPOINT'] = checkpoint\n",
        "\n",
        "%cd %cd /home/jetshu/Documents/PLAEX/code/SwAV/swav_single_gpu/\n",
        "!python eval_linear_no_distribution.py \\\n",
        "--data_path $DATASET_PATH \\\n",
        "--pretrained $EXPERIMENT_PATH/$CHECKPOINT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od5952VUIRTR"
      },
      "source": [
        "Copy final modifications into our Google Drive files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eupFqopajQDS"
      },
      "outputs": [],
      "source": [
        "#!cp -f /content/swav/eval_linear_no_distribution.py /content/drive/MyDrive/PLAEX/Selfsupervised_models/swav/code/\n",
        "#!cp -f /content/swav/src/utils.py /content/drive/MyDrive/PLAEX/Selfsupervised_models/swav/code/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slv-93R-r0gR"
      },
      "source": [
        "# **Given time limitation (<1h) in COLAB we are going to try to train locally**\n",
        "- Graph cards: GTX 1060 Ti\n",
        "- RAM: 16GB"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
